{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (2.5.1+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (2.5.1+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (70.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchsummary in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.10.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opencv-python) (1.26.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from tqdm) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pickle5\n",
      "  Using cached pickle5-0.0.11.tar.gz (132 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: pickle5\n",
      "  Building wheel for pickle5 (pyproject.toml): started\n",
      "  Building wheel for pickle5 (pyproject.toml): finished with status 'error'\n",
      "Failed to build pickle5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for pickle5 (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [15 lines of output]\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\\lib.win-amd64-cpython-312\\pickle5\n",
      "      copying pickle5\\pickle.py -> build\\lib.win-amd64-cpython-312\\pickle5\n",
      "      copying pickle5\\pickletools.py -> build\\lib.win-amd64-cpython-312\\pickle5\n",
      "      copying pickle5\\__init__.py -> build\\lib.win-amd64-cpython-312\\pickle5\n",
      "      creating build\\lib.win-amd64-cpython-312\\pickle5\\test\n",
      "      copying pickle5\\test\\pickletester.py -> build\\lib.win-amd64-cpython-312\\pickle5\\test\n",
      "      copying pickle5\\test\\test_pickle.py -> build\\lib.win-amd64-cpython-312\\pickle5\\test\n",
      "      copying pickle5\\test\\test_picklebuffer.py -> build\\lib.win-amd64-cpython-312\\pickle5\\test\n",
      "      copying pickle5\\test\\__init__.py -> build\\lib.win-amd64-cpython-312\\pickle5\\test\n",
      "      running build_ext\n",
      "      building 'pickle5._pickle' extension\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for pickle5\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pickle5)\n"
     ]
    }
   ],
   "source": [
    "##installs pytorch on a cuda-capable windows machine using pip\n",
    "\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "%pip install torchsummary\n",
    "\n",
    "%pip install numpy\n",
    "\n",
    "%pip install matplotlib\n",
    "\n",
    "%pip install opencv-python\n",
    "\n",
    "%pip install scikit-learn\n",
    "\n",
    "%pip install pandas\n",
    "\n",
    "%pip install tqdm\n",
    "\n",
    "%pip install pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: progettoVIPM\n"
     ]
    }
   ],
   "source": [
    "if(os.path.split(os.getcwd())[1] == \"Transfer_Learning\"):\n",
    "    os.chdir(\"..\")\n",
    "print(\"Current Working Directory: {}\".format(os.path.split(os.getcwd())[1]))\n",
    "\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.loadersAndEnums import datasets\n",
    "from utils.loadersAndEnums import networks\n",
    "from utils.loadersAndEnums import ImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.extractNeuralFeatures import extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original classification layers:AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "chosen_net = networks.ALEXNET\n",
    "print(\"Original classification layers:{}\".format(chosen_net.value[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found an existing set of features in: ./Storage/neural_features/Train_AlexNet_minus3_train_set.npy\n",
      "Loading features from file:\n",
      "---------------------------------------------------------------------------------\n",
      "Done feat extraction, total n° of istances in Train: 5020\n",
      "Feature vector shape of Train: (5020, 9216)\n",
      "Label vector shape of Train: (5020,)\n",
      "---------------------------------------------------------------------------------\n",
      "Found an existing set of features in: ./Storage/neural_features/Test_AlexNet_minus3_val_set.npy\n",
      "Loading features from file:\n",
      "---------------------------------------------------------------------------------\n",
      "Done feat extraction, total n° of istances in Test: 11994\n",
      "Feature vector shape of Test: (11994, 9216)\n",
      "Label vector shape of Test: (11994,)\n",
      "---------------------------------------------------------------------------------\n",
      "Original classification layers:Sequential(\n",
      "  (0): Dropout(p=0.5, inplace=False)\n",
      "  (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Dropout(p=0.5, inplace=False)\n",
      "  (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n",
      "---------------------------------------------------------------------------------\n",
      "Classification layers to fine tune:Sequential(\n",
      "  (0): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace=True)\n",
      "  (5): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# t sta per \"tensor\", ovvero il vettore sulla gpu, mentre \"n\" sta per \"numpy\", ovvero il vettore sulla cpu\n",
    "\n",
    "linear_layers_to_remove = 3\n",
    "X_train_ale_t, X_train_ale_n, y_train, X_test_ale_t, X_test_ale_n, y_test, fine_tune_layers = extract_features(train_set=datasets.TRAINING_LABELED,\n",
    "                                                                                            test_set=datasets.TEST,\n",
    "                                                                                            network=chosen_net,\n",
    "                                                                                            layers_to_remove=linear_layers_to_remove, \n",
    "                                                                                            cuda=cuda)\n",
    "print(\"Original classification layers:{}\".format(chosen_net.value[1].classifier[:]))\n",
    "print(\"---------------------------------------------------------------------------------\")\n",
    "print(\"Classification layers to fine tune:{}\".format(fine_tune_layers[:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def model_building(model, model_name, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc=accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=model.classes_)\n",
    "    disp.plot()\n",
    "    plt.savefig(\"./Transfer_Learning/model_metrics/ConfM_{}.pdf\".format(model_name))\n",
    "    cm = np.array(cm)\n",
    "    np.save(\"./Transfer_Learning/model_metrics/ConfM_{}.npy\".format(model_name), cm)\n",
    "    with open('./Storage/models/{}.pkl'.format(model_name),'wb') as f:\n",
    "        pickle.dump(model,f)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "is_pca_used = False\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(X_train_ale_n)\n",
    "pca = PCA().fit(scaled_data)\n",
    "\n",
    "plt.plot(range(1, pca.n_components_ + 1), pca.explained_variance_ratio_, marker='o')\n",
    "plt.xlabel('Componenti della PCA')\n",
    "plt.ylabel('Varianza spiegata')\n",
    "plt.title(\"Risultati della PCA\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final input shape train: (5020, 500)\n",
      "Final input shape test: (11994, 500)\n"
     ]
    }
   ],
   "source": [
    "components = 500\n",
    "pca = PCA(n_components=components).fit(scaled_data)\n",
    "X_train_pca = pca.transform(scaled_data)\n",
    "print(\"Final input shape train: {}\".format(X_train_pca.shape))\n",
    "\n",
    "scaled_data = scaler.fit_transform(X_test_ale_n)\n",
    "x_test_pca = pca.transform(scaled_data)\n",
    "print(\"Final input shape test: {}\".format(x_test_pca.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "from enum import Enum\n",
    "class ml_models(Enum):\n",
    "    LINEAR_SVC = [LinearSVC(), \"Linear Support Vector\"]\n",
    "    RBF_SVC = [SVC(kernel=\"rbf\"), \"Rbf Support Vector\"]\n",
    "    # RANDOM_FOREST = [RandomForestClassifier(), \"Random Forest\"]\n",
    "    # BOOSTED_FOREST = [GradientBoostingClassifier(), \"Gradient Boosting Classifier\"]\n",
    "    KNN_1 = [KNeighborsClassifier(n_neighbors=1), \"KNN with 1 neighbors\"]\n",
    "    KNN_10 = [KNeighborsClassifier(n_neighbors=10), \"KNN with 10 neighbors\"]\n",
    "    KNN_20 = [KNeighborsClassifier(n_neighbors=20), \"KNN with 20 neighbors\"]\n",
    "    KNN_50 = [KNeighborsClassifier(n_neighbors=50), \"KNN with 50 neighbors\"]\n",
    "    NAIVE_BAYES = [GaussianNB(), \"Naive Bayes\"]\n",
    "\n",
    "is_pca_used = True\n",
    "\n",
    "x_train = X_train_ale_n\n",
    "x_test = X_test_ale_n\n",
    "if is_pca_used:\n",
    "    x_train = X_train_pca\n",
    "    x_test =x_test_pca\n",
    "model_accuracies = []\n",
    "for model in tqdm(ml_models):    \n",
    "    model_name = \"{}_from_{}_minus{}\".format(model.value[1], chosen_net.value[2], linear_layers_to_remove)\n",
    "    if is_pca_used:\n",
    "        model_name += \"_pca\"\n",
    "    score = model_building(model.value[0], model_name, x_train, x_test, y_train, y_test)\n",
    "    print(\"{} obtained following accuracy: {}\".format(model.value[1],score))\n",
    "    model_accuracies.append([model_name, score])\n",
    "model_accuracies = np.array(model_accuracies)\n",
    "accuracies_filename = \"./Transfer_Learning/model_metrics/Accuracies_{}_minus{}\".format(chosen_net.value[2], linear_layers_to_remove)\n",
    "if is_pca_used:\n",
    "    accuracies_filename += \"_pca\"\n",
    "np.save(\"{}.npy\".format(accuracies_filename), model_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.fine_tune_pytorch import fine_tune_network_layers, eval_model_on_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m n_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m     10\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m\n\u001b[1;32m---> 11\u001b[0m trained_model, losses \u001b[38;5;241m=\u001b[39m \u001b[43mfine_tune_network_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfine_tune_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train_ale_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Uni\\primo semestre 5\\Progetto Visual\\progettoVIPM\\utils\\fine_tune_pytorch.py:33\u001b[0m, in \u001b[0;36mfine_tune_network_layers\u001b[1;34m(cuda, net_layers, x_train, y_train, n_epochs, batch_size, loss_function, optimizer)\u001b[0m\n\u001b[0;32m     30\u001b[0m training_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     31\u001b[0m validation_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 33\u001b[0m model,losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, losses\n",
      "File \u001b[1;32md:\\Uni\\primo semestre 5\\Progetto Visual\\progettoVIPM\\utils\\fine_tune_pytorch.py:51\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(training_loader, validation_loader, n_epochs, model, loss_function, optimizer)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Make sure gradient tracking is on, and do a pass over the data\u001b[39;00m\n\u001b[0;32m     50\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 51\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m running_vloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Set the model to evaluation mode, disabling dropout and using population\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# statistics for batch normalization.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Uni\\primo semestre 5\\Progetto Visual\\progettoVIPM\\utils\\fine_tune_pytorch.py:89\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(training_loader, model, loss_function, optimizer)\u001b[0m\n\u001b[0;32m     87\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m     88\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(outputs, labels)\n\u001b[1;32m---> 89\u001b[0m avg_batch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n\u001b[0;32m     92\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(fine_tune_layers.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "n_epochs = 5\n",
    "batch_size = 128\n",
    "trained_model, losses = fine_tune_network_layers(cuda, fine_tune_layers, x_train=X_train_ale_t, y_train=y_train, n_epochs=n_epochs,\n",
    "                                                 batch_size=batch_size, loss_function=loss_function, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "  x_plot = list(range(1,len(history)+1))\n",
    "  plt.figure()\n",
    "  plt.title(\"Loss\")\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.plot(x_plot, history[:,0])\n",
    "  plt.plot(x_plot, history[:,1])\n",
    "  plt.legend(['Training', 'Validation'])\n",
    "\n",
    "# print(losses)\n",
    "plot_loss(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = eval_model_on_test_set(trained_model, model_name=\"Alexnet\", target_dir=\"Transfer_Learning\", x_test=X_test_ale_t, y_test=y_test, cuda=cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboardX\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy in d:\\uni\\primo semestre 5\\progetto visual\\progettovipm\\env\\lib\\site-packages (from tensorboardX) (1.26.3)\n",
      "Requirement already satisfied: packaging in d:\\uni\\primo semestre 5\\progetto visual\\progettovipm\\env\\lib\\site-packages (from tensorboardX) (24.2)\n",
      "Requirement already satisfied: protobuf>=3.20 in d:\\uni\\primo semestre 5\\progetto visual\\progettovipm\\env\\lib\\site-packages (from tensorboardX) (5.29.2)\n",
      "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "Installing collected packages: tensorboardX\n",
      "Successfully installed tensorboardX-2.6.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer, training_loader, model, loss_function, optimizer):\n",
    "    running_loss = 0.\n",
    "    avg_batch_loss = 0.\n",
    "    n_batch = 0\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_function(outputs, labels)\n",
    "        avg_batch_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        # running_loss += loss.item()\n",
    "        # if i % 10 == 9:\n",
    "        #     last_loss = running_loss / 10 # loss per batch\n",
    "        #     print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "        #     tb_x = epoch_index * len(training_loader) + i + 1\n",
    "        #     tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "        #     running_loss = 0.\n",
    "        n_batch += 1\n",
    "\n",
    "    return avg_batch_loss/n_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "from IPython.display import clear_output\n",
    "def train_model(training_loader, validation_loader, n_epochs, model, loss_function, optimizer):\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    writer = SummaryWriter('runs/trainer_{}'.format(timestamp))\n",
    "\n",
    "    epoch_number = 0\n",
    "\n",
    "\n",
    "    best_vloss = 1_000_000.\n",
    "\n",
    "    losses = np.empty((n_epochs,2))\n",
    "\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        clear_output(wait=True)\n",
    "        print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "        # Make sure gradient tracking is on, and do a pass over the data\n",
    "        model.train(True)\n",
    "        avg_loss = train_one_epoch(epoch_number, writer, training_loader, model, loss_function, optimizer)\n",
    "\n",
    "\n",
    "        running_vloss = 0.0\n",
    "        # Set the model to evaluation mode, disabling dropout and using population\n",
    "        # statistics for batch normalization.\n",
    "        model.eval()\n",
    "\n",
    "        # Disable gradient computation and reduce memory consumption.\n",
    "        with torch.no_grad():\n",
    "            for i, vdata in enumerate(validation_loader):\n",
    "                vinputs, vlabels = vdata\n",
    "                voutputs = model(vinputs)\n",
    "                vloss = loss_function(voutputs, vlabels)\n",
    "                running_vloss += vloss.item()\n",
    "\n",
    "        avg_vloss = running_vloss / (i + 1)\n",
    "        losses[epoch_number] = [avg_loss, avg_vloss]\n",
    "        print('LOSS: train {}; valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "        # Log the running loss averaged per batch\n",
    "        # for both training and validation\n",
    "        writer.add_scalars('Training vs. Validation Loss',\n",
    "                        { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                        epoch_number + 1)\n",
    "        writer.flush()\n",
    "\n",
    "        # Track best performance, and save the model's state\n",
    "        # if avg_vloss < best_vloss:\n",
    "        #     best_vloss = avg_vloss\n",
    "        #     model_path = './Transfer_Learning/models/neural/model_{}_{}'.format(timestamp, epoch_number)\n",
    "        #     torch.save(model.state_dict(), model_path)\n",
    "\n",
    "        epoch_number += 1\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11994/11994 [00:07<00:00, 1618.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1424045356011339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trained_model.eval()\n",
    "\n",
    "predictions = np.zeros(len(test_loader))\n",
    "# Disable gradient computation and reduce memory consumption.\n",
    "with torch.no_grad():\n",
    "    i = 0\n",
    "    for test_data in tqdm(test_loader):\n",
    "        test_features, test_labels = test_data\n",
    "        predictions[i] = np.argmax(np.array(trained_model(test_features).cpu()))\n",
    "        i+=1\n",
    "y_test = np.array(y_test.cpu())\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: {}\".format(accuracy))\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm = np.array(cm)\n",
    "model_name=\"Alexnet\"\n",
    "np.save(\"./Transfer_Learning/model_metrics/ConfM_{}.npy\".format(model_name), cm)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
