{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.20.1)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchaudio-2.5.1%2Bcu118-cp312-cp312-win_amd64.whl (4.0 MB)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (70.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torch-2.5.1%2Bcu118-cp312-cp312-win_amd64.whl (2700.1 MB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Installing collected packages: torch, torchaudio\n",
      "Successfully installed torch-2.5.1+cu118 torchaudio-2.5.1+cu118\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --user torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3373289064.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "##installs pytorch on a cuda-capable windows machine using pip\n",
    "\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "%pip install torchsummary\n",
    "\n",
    "%pip install numpy\n",
    "\n",
    "%pip install matplotlib\n",
    "\n",
    "%pip install opencv-python\n",
    "\n",
    "%pip install scikit-learn\n",
    "\n",
    "%pip install pandas\n",
    "\n",
    "%pip install pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: progettoVIPM\n"
     ]
    }
   ],
   "source": [
    "if(os.path.split(os.getcwd())[1] == \"Transfer_Learning\" or os.path.split(os.getcwd())[1] == \"semi-supervised\"):\n",
    "    os.chdir(\"..\")\n",
    "print(\"Current Working Directory: {}\".format(os.path.split(os.getcwd())[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from enum import Enum\n",
    "\n",
    "class datasets(Enum):\n",
    "    TRAINING_LABELED = [\"train_small.csv\", \"train_set\"]\n",
    "    TRAINING_UNLABELED = [\"train_unlabeled.csv\", \"train_set\"]\n",
    "    TEST = [\"val_info.csv\", \"val_set\"]\n",
    "    TEST_DEGRADED = [\"val_info.csv\", \"val_set_degraded\"]\n",
    "\n",
    "class networks(Enum):\n",
    "    ALEXNET = [227, models.alexnet(pretrained=True), \"AlexNet\"] #227?\n",
    "    RESNET50 = [224, models.resnet50(pretrained=True), \"ResNet50\"]\n",
    "    GOOGLENET = [224, models.googlenet(pretrained=True), \"GoogLeNet\"]\n",
    "    MOBILENET = [224, models.mobilenet_v3_small(pretrained=True), \"mobilenet_v3_small\"]\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, dataset, network_input_size):\n",
    "        super().__init__()\n",
    "        self.images_names = []\n",
    "        self.labels = []\n",
    "        dataset = dataset.value\n",
    "        annotations_file = dataset[0]\n",
    "        img_dir = dataset[1]\n",
    "        with open(annotations_file, newline='') as csvfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            for row in reader:\n",
    "                self.images_names.append(\"./{}/{}\".format(img_dir, row[0]))\n",
    "                self.labels.append(row[1])\n",
    "        self.images_names = np.array(self.images_names)\n",
    "        self.labels = np.array(self.labels)\n",
    "        # in base al valore passato si sceglie la rete che utilizzerà il dataset, serve per modificare le dimensioni delle immagini\n",
    "        self.im_size = network_input_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_bgr = cv2.resize((cv2.imread(self.images_names[index], cv2.IMREAD_COLOR).astype(np.double)/255), \n",
    "                                       (self.im_size,self.im_size), \n",
    "                                        interpolation=cv2.INTER_CUBIC).astype(np.float32)\n",
    "        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "        #moveaxis serve per avere come dimensione dell'immagine (3, righe, colonne) invece di (righe, colonne, 3)\n",
    "        image = np.moveaxis(image_rgb, -1, 0)\n",
    "        # eventualmente si può aggiungere l'alternativa di fare random cropping dell'immagine\n",
    "        label = self.labels[index]           \n",
    "        if(cuda):\n",
    "            return torch.from_numpy(image).cuda(), label\n",
    "        else:\n",
    "            return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n",
    "from copy import deepcopy\n",
    "\n",
    "def extract_features_of_dataset(dataset, dataset_type, input_size, transfer_network, data_file):\n",
    "    if(os.path.exists(data_file)):\n",
    "        numpy_feat = np.load(data_file).astype(\"float32\")\n",
    "        if(cuda):            \n",
    "            net_features = torch.from_numpy(numpy_feat).to(device=\"cuda\")  \n",
    "        else:\n",
    "            net_features=-1\n",
    "        y = [] #if the dataset is unlabled it will remain empty\n",
    "        if (dataset_type != \"unlabled\"):    \n",
    "            annotations_file = dataset.value[0]\n",
    "            with open(annotations_file, newline='') as csvfile:\n",
    "                reader = csv.reader(csvfile)\n",
    "                for row in reader:\n",
    "                    y.append(row[1])\n",
    "            y = np.array(y).astype(\"int\")        \n",
    "    else:\n",
    "        dataset_holder = ImageDataset(dataset=dataset, network_input_size=input_size)\n",
    "        loader = DataLoader(dataset=dataset_holder, shuffle=False, batch_size=1)\n",
    "\n",
    "        if(cuda):      \n",
    "            net_features = torch.zeros(len(dataset_holder), transfer_network.classifier[-1].out_features)\n",
    "            y = np.zeros(len(dataset_holder)).astype(\"int\")\n",
    "            transfer_network.eval()\n",
    "            with torch.no_grad():\n",
    "                i = 0               \n",
    "                print(\"extracting features:\")\n",
    "                for X_batch, y_batch in tqdm(loader):\n",
    "                    net_features[i]=transfer_network(X_batch)                           \n",
    "                    if (dataset_type != \"unlabled\"):  \n",
    "                        y[i] = y_batch[0]\n",
    "                    i=i+1    \n",
    "                    \n",
    "            #The following code copies the neural features to a numpy array stored in the cpu in order to use it in sklearn(non-neural) classifiers\n",
    "            numpy_feat = np.zeros(net_features.shape)\n",
    "            i = 0 \n",
    "            print(\"copying features:\")\n",
    "            for i in tqdm(range(len(net_features))):\n",
    "                numpy_feat[i]= net_features[i].cpu().numpy()    \n",
    "            np.save(data_file, numpy_feat)\n",
    "\n",
    "        else: #non-cuda case\n",
    "            \n",
    "            net_features=-1\n",
    "            numpy_feat = np.zeros((len(dataset_holder), transfer_network.classifier[-1].out_features))\n",
    "            y = np.zeros(len(dataset_holder)).astype(\"int\")\n",
    "            transfer_network.eval()\n",
    "            with torch.no_grad():\n",
    "                i = 0               \n",
    "                print(\"extracting features:\")\n",
    "                for X_batch, y_batch in tqdm(loader):\n",
    "                    numpy_feat[i]=transfer_network(X_batch)                           \n",
    "                    if (dataset_type != \"unlabled\"):  \n",
    "                        y[i] = y_batch[0]\n",
    "                    i=i+1    \n",
    "            np.save(data_file, numpy_feat)\n",
    "            \n",
    "    print(\"Done feat extraction, total n° of istances in {}: {}\".format(dataset_type, len(numpy_feat)))\n",
    "    print(\"Feature vector shape of {}: {}\".format(dataset_type, numpy_feat.shape))\n",
    "    if (dataset_type != \"unlabled\"):  \n",
    "        print(\"Label vector shape of {}: {}\".format(dataset_type, y.shape))\n",
    "\n",
    "    return net_features, numpy_feat, y\n",
    "    \n",
    "\n",
    "def extrac_features(train_set, test_set, network, layers_to_remove):\n",
    "    \n",
    "    net_input_size = network.value[0]\n",
    "    net = deepcopy(network.value[1])\n",
    "    if (cuda):\n",
    "        net.cuda()\n",
    "    fine_tune_layers = nn.Sequential(*[net.classifier[i] for i in range((len(net.classifier) - layers_to_remove), len(net.classifier))])\n",
    "    net.classifier = nn.Sequential(*[net.classifier[i] for i in range(len(net.classifier) - layers_to_remove)])\n",
    "\n",
    "    train_data_file = \"./Transfer_Learning/neural_features/Train_{}_minus{}_{}.npy\".format(network.value[2], layers_to_remove, train_set.value[1])\n",
    "    net_features_train, numpy_feat_train, y_train = extract_features_of_dataset(dataset=train_set, dataset_type=\"Train\",\n",
    "                                                                                input_size=net_input_size,\n",
    "                                                                                transfer_network=net,data_file=train_data_file)\n",
    "    \n",
    "    test_data_file = \"./Transfer_Learning/neural_features/Test_{}_minus{}_{}.npy\".format(network.value[2], layers_to_remove, test_set.value[1])\n",
    "    net_features_test, numpy_feat_test, y_test = extract_features_of_dataset(dataset=test_set, dataset_type=\"Test\",\n",
    "                                                                                input_size=net_input_size,\n",
    "                                                                                transfer_network=net,data_file=test_data_file)\n",
    "    \n",
    "    return net_features_train, numpy_feat_train, y_train, net_features_test, numpy_feat_test, y_test, fine_tune_layers\n",
    "    \n",
    "\n",
    "    \n",
    "def extrac_features_from_unlabled_dataset(dataset, network, layers_to_remove):\n",
    "    \n",
    "    net_input_size = network.value[0]\n",
    "    net = deepcopy(network.value[1])\n",
    "    \n",
    "    fine_tune_layers = nn.Sequential(*[net.classifier[i] for i in range((len(net.classifier) - layers_to_remove), len(net.classifier))])\n",
    "    net.classifier = nn.Sequential(*[net.classifier[i] for i in range(len(net.classifier) - layers_to_remove)])\n",
    "\n",
    "    unlabled_data_file = \"./Transfer_Learning/neural_features/Unlabled_{}_minus{}_{}.npy\".format(network.value[2], layers_to_remove, dataset.value[1])\n",
    "    net_features, numpy_feat, y = extract_features_of_dataset(dataset=dataset, dataset_type=\"unlabled\",\n",
    "                                                                                input_size=net_input_size,\n",
    "                                                                                transfer_network=net,data_file=unlabled_data_file)  \n",
    "    fake_labels = [-1 for _ in range(len(numpy_feat))]  \n",
    "    return net_features, numpy_feat, fake_labels, fine_tune_layers\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done feat extraction, total n° of istances in Train: 5020\n",
      "Feature vector shape of Train: (5020, 1024)\n",
      "Label vector shape of Train: (5020,)\n",
      "Done feat extraction, total n° of istances in Test: 11994\n",
      "Feature vector shape of Test: (11994, 1024)\n",
      "Label vector shape of Test: (11994,)\n",
      "Original classification layers:Sequential(\n",
      "  (0): Linear(in_features=576, out_features=1024, bias=True)\n",
      "  (1): Hardswish()\n",
      "  (2): Dropout(p=0.2, inplace=True)\n",
      "  (3): Linear(in_features=1024, out_features=1000, bias=True)\n",
      ")\n",
      "Classification layers to fine tune:Sequential(\n",
      "  (0): Hardswish()\n",
      "  (1): Dropout(p=0.2, inplace=True)\n",
      "  (2): Linear(in_features=1024, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# t sta per \"tensor\", ovvero il vettore sulla gpu, mentre \"n\" sta per \"numpy\", ovvero il vettore sulla cpu\n",
    "chosen_net = networks.MOBILENET\n",
    "layers_to_remove = 3\n",
    "X_train_mobi_t, X_train_mobi_n, y_train, X_test_mobi_t, X_test_mobi_n, y_test, fine_tune_layers = extrac_features(train_set=datasets.TRAINING_LABELED,\n",
    "                                                                                            test_set=datasets.TEST,\n",
    "                                                                                            network=chosen_net,\n",
    "                                                                                            layers_to_remove=layers_to_remove)\n",
    "print(\"Original classification layers:{}\".format(chosen_net.value[1].classifier[:]))\n",
    "print(\"Classification layers to fine tune:{}\".format(fine_tune_layers[:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5020, 1024)\n",
      "(5020,)\n",
      "(11994, 1024)\n",
      "(11994,)\n"
     ]
    }
   ],
   "source": [
    "if (cuda):\n",
    "    print(X_train_mobi_t.shape)\n",
    "print(X_train_mobi_n.shape)\n",
    "print(y_train.shape)\n",
    "if (cuda):\n",
    "    print(X_test_mobi_t.shape)\n",
    "print(X_test_mobi_n.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done feat extraction, total n° of istances in unlabled: 113455\n",
      "Feature vector shape of unlabled: (113455, 1024)\n",
      "Original classification layers:Sequential(\n",
      "  (0): Linear(in_features=576, out_features=1024, bias=True)\n",
      "  (1): Hardswish()\n",
      "  (2): Dropout(p=0.2, inplace=True)\n",
      "  (3): Linear(in_features=1024, out_features=1000, bias=True)\n",
      ")\n",
      "Classification layers to fine tune:Sequential(\n",
      "  (0): Hardswish()\n",
      "  (1): Dropout(p=0.2, inplace=True)\n",
      "  (2): Linear(in_features=1024, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# t sta per \"tensor\", ovvero il vettore sulla gpu, mentre \"n\" sta per \"numpy\", ovvero il vettore sulla cpu\n",
    "chosen_net = networks.MOBILENET\n",
    "layers_to_remove = 3\n",
    "X_unlabled_mobi_t, X_unlabled_mobi_n, fake_labels, fine_tune_layers = extrac_features_from_unlabled_dataset(dataset=datasets.TRAINING_UNLABELED,\n",
    "                                                                                            network=chosen_net,\n",
    "                                                                                            layers_to_remove=layers_to_remove)\n",
    "print(\"Original classification layers:{}\".format(chosen_net.value[1].classifier[:]))\n",
    "print(\"Classification layers to fine tune:{}\".format(fine_tune_layers[:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113455, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(X_unlabled_mobi_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = X_unlabled_mobi_n.shape[0]\n",
    "partOfUnlabeledToSelect = 0.10\n",
    "num_samples = int(num_rows * partOfUnlabeledToSelect)\n",
    "np.random.seed(42)\n",
    "# Get random indices\n",
    "random_indices = np.random.choice(num_rows, num_samples, replace=False)\n",
    "\n",
    "# Select the random rows\n",
    "X_selected = X_unlabled_mobi_n[random_indices, :]\n",
    "#y_selected = fake_labels[random_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16365, 1024)\n",
      "(16365,)\n"
     ]
    }
   ],
   "source": [
    "X_train_mixed = np.concatenate((X_train_mobi_n, X_selected))#prima era X_train_mobi_n, X_unlabled_mobi_n\n",
    "print(X_train_mixed.shape)\n",
    "y_train_mixed = np.concatenate((y_train, fake_labels[:num_samples]))#prima era y_train, fake_labels\n",
    "print(y_train_mixed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def model_building(model, model_name, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc=accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=model.classes_)\n",
    "    disp.plot()\n",
    "    plt.savefig(\"./semi-supervised/model_metrics/ConfM_{}.pdf\".format(model_name))\n",
    "    cm = np.array(cm)\n",
    "    np.save(\"./semi-supervised/model_metrics/ConfM_{}.npy\".format(model_name), cm)\n",
    "    with open('./semi-supervised/models/{}.pkl'.format(model_name),'wb') as f:\n",
    "        pickle.dump(model,f)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finito di inferire le labels sugli non annotati\n",
      "finito di fittare il classificatore\n",
      "Accuracy: 6.053\n"
     ]
    }
   ],
   "source": [
    "from sklearn.semi_supervised import LabelSpreading\n",
    "\n",
    "model  = [LabelSpreading(kernel=\"knn\", max_iter=5, n_jobs=-1, n_neighbors=3), \"LabelSpreading\"]\n",
    "model[0].fit( X_train_mixed, y_train_mixed)\n",
    "print(\"finito di inferire le labels sugli non annotati\")\n",
    "\n",
    "guessedAndRealLabels = model[0].transduction_\n",
    "\n",
    "\n",
    "model2 = RandomForestClassifier()\n",
    "model2.fit(X_train_mixed, guessedAndRealLabels) \n",
    "print(\"finito di fittare il classificatore\")\n",
    "guessedTestLabels = model2.predict(X_test_mobi_n)\n",
    "score = accuracy_score(y_test, guessedTestLabels)\n",
    "# summarize score\n",
    "print('Accuracy: %.3f' % (score*100))\n",
    "np.save(\"./semi-supervised/model_metrics/Accuracies_{}_minus{}_randomForest_labelSpreading_{}_ofunlabeled.npy\".format(chosen_net, layers_to_remove, partOfUnlabeledToSelect), score)\n",
    "# 5% unlabeled ->6.9 di acc\n",
    "# 10% unlabeled ->6.9 di acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
