{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: progettoVIPM\n"
     ]
    }
   ],
   "source": [
    "if(os.path.split(os.getcwd())[1] == \"misc\"):\n",
    "    os.chdir(\"..\")\n",
    "print(\"Current Working Directory: {}\".format(os.path.split(os.getcwd())[1]))\n",
    "\n",
    "cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.loadersAndEnums import datasets\n",
    "from utils.loadersAndEnums import networks\n",
    "from utils.loadersAndEnums import ImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VALIDATION SET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPARSE AUTOENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseAutoencoderL1(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (3): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (6): ConvTranspose2d(16, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.sparseAutoencoder import SparseAutoencoderL1\n",
    "best_model_path = 'self-supervised/models/best_sparse_AE.pth'\n",
    "sparseAE = SparseAutoencoderL1()\n",
    "sparseAE.load_state_dict(torch.load(best_model_path))\n",
    "sparseAE.eval()  # Set the model to evaluation mode\n",
    "sparseAE.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtendedEncoderV2(nn.Module):\n",
    "    def __init__(self, base_encoder):\n",
    "        super(ExtendedEncoderV2, self).__init__()\n",
    "        self.base_encoder = base_encoder\n",
    "\n",
    "        # Additional convolutional and ReLU layers\n",
    "        self.additional_conv = nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.additional_relu = nn.ReLU()\n",
    "\n",
    "        # Dynamically compute flatten_dim\n",
    "        dummy_input = torch.randn(1, 3, 256, 256).to(device)  # Simulate input\n",
    "        self.additional_conv.to(device)  # Move additional_conv to the same device\n",
    "        dummy_output = self.base_encoder(dummy_input)  # Get encoder output\n",
    "        dummy_output = self.additional_conv(dummy_output)  # Pass through additional conv layer\n",
    "        dummy_output = self.additional_relu(dummy_output)  # Pass through additional ReLU layer\n",
    "        self.flatten_dim = dummy_output.view(1, -1).size(1)  # Flatten dimension\n",
    "\n",
    "        # Fully connected layers with dropout\n",
    "        self.fc1 = nn.Linear(self.flatten_dim, 260)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(260, 251)\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        # Freeze base encoder weights\n",
    "        for param in self.base_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_encoder(x)  # Base encoder\n",
    "        x = self.additional_conv(x)  # Additional conv layer\n",
    "        x = self.additional_relu(x)  # Additional ReLU layer\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc1(x)  # Fully connected layer\n",
    "        x = self.relu(x)  # ReLU activation\n",
    "        x = self.dropout1(x)  # Dropout\n",
    "        x = self.fc2(x)  # Fully connected layer\n",
    "        x = self.dropout2(x)  # Dropout\n",
    "        x = self.softmax(x)  # Softmax activation\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "val = ImageDataset(datasets.VALIDATION_LABELED_20,256,True)\n",
    "val = DataLoader(val,batch_size=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:04<00:00, 202.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.796812749003984\n",
      "5-Accuracy: 2.091633466135458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "exEncoder = ExtendedEncoderV2(sparseAE.encoder)\n",
    "exEncoder.load_state_dict(torch.load(\"self-supervised/models/best_AE_classifier.pth\"))\n",
    "exEncoder.to(device)\n",
    "from utils.fine_tune_pytorch import eval_model_on_test_loader\n",
    "\n",
    "cm = eval_model_on_test_loader(exEncoder, \"sparse_encoder_classifier\", \"misc\", val, True, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COLORIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:14<00:00, 68.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0956175298804782\n",
      "5-Accuracy: 3.386454183266932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "class ColorizationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ColorizationModel, self).__init__()\n",
    "        # Encoder: Convolutional layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Output size: 64 x 128 x 128\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # Output size: 128 x 64 x 64\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) # Output size: 256 x 32 x 32\n",
    "        )\n",
    "        # Decoder: Deconvolutional layers\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 2, kernel_size=4, stride=2, padding=1),  # Output 2 channels (a, b)\n",
    "            nn.Tanh()  # Normalize output to range [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        output = self.decoder(features)\n",
    "        return output\n",
    "    \n",
    "best_model_path = 'self-supervised/models/best_Colorizer.pth'\n",
    "\n",
    "colorizer = ColorizationModel()\n",
    "colorizer.load_state_dict(torch.load(best_model_path))\n",
    "colorizer.to(device)\n",
    "class ExtendedColorizerLinear(nn.Module):\n",
    "    def __init__(self, colorizer):\n",
    "        super(ExtendedColorizerLinear, self).__init__()\n",
    "        self.encoder = colorizer.encoder\n",
    "        self.ff1 = nn.Linear(256*32*32, 1024)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.ff2 = nn.Linear(1024, 251)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(-1, 256*32*32)\n",
    "        x = self.ff1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "exColorizer = ExtendedColorizerLinear(colorizer)\n",
    "\n",
    "best_model_path = 'self-supervised/models/best_LinearColorizer_classifier.pth'\n",
    "\n",
    "exColorizer.load_state_dict(torch.load(best_model_path))\n",
    "exColorizer.to(device)\n",
    "def process_batch(batch):\n",
    "    batch = batch.cpu().numpy()\n",
    "    batch = np.moveaxis(batch, 1, -1)  # Move channel axis to the end\n",
    "    lab_batch = np.array([cv2.cvtColor(img, cv2.COLOR_RGB2LAB) for img in batch])\n",
    "    \n",
    "    L_batch = lab_batch[:,:,:,0] / 255.0\n",
    "    ab_batch = lab_batch[:,:,:,1:] / 128.0\n",
    "    \n",
    "    L_batch = torch.tensor(L_batch, dtype=torch.float32).unsqueeze(1)  # Add channel dimension\n",
    "    ab_batch = torch.tensor(ab_batch, dtype=torch.float32).permute(0, 3, 1, 2)  # Move channel axis to the second position\n",
    "    \n",
    "    return L_batch, ab_batch\n",
    "\n",
    "k = 5\n",
    "k_correct = 0\n",
    "total = len(val)\n",
    "exColorizer.eval()\n",
    "predictions = np.zeros(len(val))\n",
    "# Disable gradient computation and reduce memory consumption.\n",
    "y_test = np.zeros(len(val))\n",
    "with torch.no_grad():\n",
    "    i = 0\n",
    "    for test_data in tqdm(val):\n",
    "        test_features, test_labels = test_data\n",
    "        test_features,_ = process_batch(test_features)\n",
    "        test_features = test_features.to(device)\n",
    "        y_test[i] = test_labels.cpu()\n",
    "        outputs = exColorizer(test_features)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions[i] = predicted.item()\n",
    "        _, indexes = torch.sort(outputs, descending=True)\n",
    "        indexes = indexes[0,0:k]\n",
    "        if y_test[i] in indexes:\n",
    "            k_correct += 1\n",
    "        i+=1\n",
    "\n",
    "k_accuracy = 100*(k_correct/total)\n",
    "accuracy = 100*accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: {}\".format(accuracy))\n",
    "print(\"{}-Accuracy: {}\".format(k, k_accuracy))\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm = np.array(cm)\n",
    "np.save(\"./{}/model_metrics/ConfM_{}.npy\".format(\"misc\", \"Linear_Colorizer_Classifier\"), cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COLORIZER + DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:14<00:00, 69.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.49800796812749004\n",
      "5-Accuracy: 2.788844621513944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "class ColorizationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ColorizationModel, self).__init__()\n",
    "        # Encoder: Convolutional layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Output size: 64 x 128 x 128\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # Output size: 128 x 64 x 64\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) # Output size: 256 x 32 x 32\n",
    "        )\n",
    "        # Decoder: Deconvolutional layers\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 2, kernel_size=4, stride=2, padding=1),  # Output 2 channels (a, b)\n",
    "            nn.Tanh()  # Normalize output to range [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        output = self.decoder(features)\n",
    "        return output\n",
    "    \n",
    "best_model_path = 'self-supervised/models/best_Colorizer.pth'\n",
    "\n",
    "colorizer = ColorizationModel()\n",
    "colorizer.load_state_dict(torch.load(best_model_path))\n",
    "colorizer.to(device)\n",
    "class ExtendedColorizerLinear(nn.Module):\n",
    "    def __init__(self, colorizer):\n",
    "        super(ExtendedColorizerLinear, self).__init__()\n",
    "        self.encoder = colorizer.encoder\n",
    "        self.ff1 = nn.Linear(256*32*32, 1024)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.ff2 = nn.Linear(1024, 251)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(-1, 256*32*32)\n",
    "        x = self.ff1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "exColorizer = ExtendedColorizerLinear(colorizer)\n",
    "\n",
    "best_model_path = 'self-supervised/models/best_Augmented_LinearColorizer_classifier.pth'\n",
    "\n",
    "exColorizer.load_state_dict(torch.load(best_model_path))\n",
    "exColorizer.to(device)\n",
    "def process_batch(batch):\n",
    "    batch = batch.cpu().numpy()\n",
    "    batch = np.moveaxis(batch, 1, -1)  # Move channel axis to the end\n",
    "    lab_batch = np.array([cv2.cvtColor(img, cv2.COLOR_RGB2LAB) for img in batch])\n",
    "    \n",
    "    L_batch = lab_batch[:,:,:,0] / 255.0\n",
    "    ab_batch = lab_batch[:,:,:,1:] / 128.0\n",
    "    \n",
    "    L_batch = torch.tensor(L_batch, dtype=torch.float32).unsqueeze(1)  # Add channel dimension\n",
    "    ab_batch = torch.tensor(ab_batch, dtype=torch.float32).permute(0, 3, 1, 2)  # Move channel axis to the second position\n",
    "    \n",
    "    return L_batch, ab_batch\n",
    "\n",
    "k = 5\n",
    "k_correct = 0\n",
    "total = len(val)\n",
    "exColorizer.eval()\n",
    "predictions = np.zeros(len(val))\n",
    "# Disable gradient computation and reduce memory consumption.\n",
    "y_test = np.zeros(len(val))\n",
    "with torch.no_grad():\n",
    "    i = 0\n",
    "    for test_data in tqdm(val):\n",
    "        test_features, test_labels = test_data\n",
    "        test_features,_ = process_batch(test_features)\n",
    "        test_features = test_features.to(device)\n",
    "        y_test[i] = test_labels.cpu()\n",
    "        outputs = exColorizer(test_features)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions[i] = predicted.item()\n",
    "        _, indexes = torch.sort(outputs, descending=True)\n",
    "        indexes = indexes[0,0:k]\n",
    "        if y_test[i] in indexes:\n",
    "            k_correct += 1\n",
    "        i+=1\n",
    "\n",
    "k_accuracy = 100*(k_correct/total)\n",
    "accuracy = 100*accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: {}\".format(accuracy))\n",
    "print(\"{}-Accuracy: {}\".format(k, k_accuracy))\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm = np.array(cm)\n",
    "np.save(\"./{}/model_metrics/ConfM_{}.npy\".format(\"misc\", \"Augmented_Linear_Colorizer_Classifier\"), cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COLORIZER + LABELS CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:15<00:00, 64.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.398406374501992\n",
      "5-Accuracy: 2.49003984063745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "class ColorizationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ColorizationModel, self).__init__()\n",
    "        # Encoder: Convolutional layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Output size: 64 x 128 x 128\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # Output size: 128 x 64 x 64\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) # Output size: 256 x 32 x 32\n",
    "        )\n",
    "        # Decoder: Deconvolutional layers\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 2, kernel_size=4, stride=2, padding=1),  # Output 2 channels (a, b)\n",
    "            nn.Tanh()  # Normalize output to range [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        output = self.decoder(features)\n",
    "        return output\n",
    "    \n",
    "best_model_path = 'self-supervised/models/best_Colorizer.pth'\n",
    "\n",
    "colorizer = ColorizationModel()\n",
    "colorizer.load_state_dict(torch.load(best_model_path))\n",
    "colorizer.to(device)\n",
    "class ExtendedColorizerLinear(nn.Module):\n",
    "    def __init__(self, colorizer):\n",
    "        super(ExtendedColorizerLinear, self).__init__()\n",
    "        self.encoder = colorizer.encoder\n",
    "        self.ff1 = nn.Linear(256*32*32, 1024)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.ff2 = nn.Linear(1024, 251)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(-1, 256*32*32)\n",
    "        x = self.ff1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "exColorizer = ExtendedColorizerLinear(colorizer)\n",
    "\n",
    "best_model_path = 'self-supervised/models/best_Label_Extended_LinearColorizer_classifier.pth'\n",
    "\n",
    "exColorizer.load_state_dict(torch.load(best_model_path))\n",
    "exColorizer.to(device)\n",
    "def process_batch(batch):\n",
    "    batch = batch.cpu().numpy()\n",
    "    batch = np.moveaxis(batch, 1, -1)  # Move channel axis to the end\n",
    "    lab_batch = np.array([cv2.cvtColor(img, cv2.COLOR_RGB2LAB) for img in batch])\n",
    "    \n",
    "    L_batch = lab_batch[:,:,:,0] / 255.0\n",
    "    ab_batch = lab_batch[:,:,:,1:] / 128.0\n",
    "    \n",
    "    L_batch = torch.tensor(L_batch, dtype=torch.float32).unsqueeze(1)  # Add channel dimension\n",
    "    ab_batch = torch.tensor(ab_batch, dtype=torch.float32).permute(0, 3, 1, 2)  # Move channel axis to the second position\n",
    "    \n",
    "    return L_batch, ab_batch\n",
    "\n",
    "k = 5\n",
    "k_correct = 0\n",
    "total = len(val)\n",
    "exColorizer.eval()\n",
    "predictions = np.zeros(len(val))\n",
    "# Disable gradient computation and reduce memory consumption.\n",
    "y_test = np.zeros(len(val))\n",
    "with torch.no_grad():\n",
    "    i = 0\n",
    "    for test_data in tqdm(val):\n",
    "        test_features, test_labels = test_data\n",
    "        test_features,_ = process_batch(test_features)\n",
    "        test_features = test_features.to(device)\n",
    "        y_test[i] = test_labels.cpu()\n",
    "        outputs = exColorizer(test_features)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions[i] = predicted.item()\n",
    "        _, indexes = torch.sort(outputs, descending=True)\n",
    "        indexes = indexes[0,0:k]\n",
    "        if y_test[i] in indexes:\n",
    "            k_correct += 1\n",
    "        i+=1\n",
    "\n",
    "k_accuracy = 100*(k_correct/total)\n",
    "accuracy = 100*accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: {}\".format(accuracy))\n",
    "print(\"{}-Accuracy: {}\".format(k, k_accuracy))\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm = np.array(cm)\n",
    "np.save(\"./{}/model_metrics/ConfM_{}.npy\".format(\"misc\", \"Label_Extended_Linear_Colorizer_Classifier\"), cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRETRAINED RESNET 50 (FOOD101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:10<00:00, 91.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 32.669322709163346\n",
      "5-Accuracy: 59.26294820717132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "val = ImageDataset(datasets.VALIDATION_LABELED_20,224,True)\n",
    "val = DataLoader(val,batch_size=1,shuffle=False)\n",
    "model = models.resnet50()\n",
    "num_classes = 251\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load(\"Transfer_Learning/models/best_FineTuned_ResNet50.pth\"))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "from utils.fine_tune_pytorch import eval_model_on_test_loader\n",
    "\n",
    "cm = eval_model_on_test_loader(model, \"finetuned_pretrained_ResNet50_classifier\", \"misc\", val, True, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRETRAINED RESNET 50 (IMAGENET1K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:11<00:00, 84.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 25.39840637450199\n",
      "5-Accuracy: 49.40239043824701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "num_classes = 251\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load(\"Transfer_Learning/models/best_FineTuned_ResNet50_NO_FREEZE.pth\"))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "from torch.utils.data import DataLoader\n",
    "val = ImageDataset(datasets.VALIDATION_LABELED_20,224,True)\n",
    "val = DataLoader(val,batch_size=1,shuffle=False)\n",
    "from utils.fine_tune_pytorch import eval_model_on_test_loader\n",
    "cm = eval_model_on_test_loader(model, \"finetuned_pretrained_ResNet50_ImageNet_NO_FREEZE_classifier\", \"misc\", val, True, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST SETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRETRAINED RESNET50 (FOOD101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B.: Results are in order: TEST, TEST_DEGRADED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11994/11994 [02:13<00:00, 89.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 39.73653493413373\n",
      "5-Accuracy: 67.60046690011673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11994/11994 [02:13<00:00, 89.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 26.721694180423544\n",
      "5-Accuracy: 48.79939969984993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "test = ImageDataset(datasets.TEST,224,True)\n",
    "test = DataLoader(test,batch_size=1,shuffle=False)\n",
    "model = models.resnet50()\n",
    "num_classes = 251\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load(\"Transfer_Learning/models/best_FineTuned_ResNet50.pth\"))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "from utils.fine_tune_pytorch import eval_model_on_test_loader\n",
    "\n",
    "cm = eval_model_on_test_loader(model, \"finetuned_pretrained_ResNet50_Food101_classifier_test\", \"misc\", test, True, 5)\n",
    "testD = ImageDataset(datasets.TEST_DEGRADED,224,True)\n",
    "testD = DataLoader(testD,batch_size=1,shuffle=False)\n",
    "cm = eval_model_on_test_loader(model, \"finetuned_pretrained_ResNet50_Food101_classifier_test_degraded\", \"misc\", testD, True, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRETRAINED RESNET50 (IMAGENET1K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11994/11994 [02:06<00:00, 95.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 29.87326996831749\n",
      "5-Accuracy: 55.61113890278473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11994/11994 [02:05<00:00, 95.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 18.325829581457395\n",
      "5-Accuracy: 36.87677171919293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "test = ImageDataset(datasets.TEST,224,True)\n",
    "test = DataLoader(test,batch_size=1,shuffle=False)\n",
    "model = models.resnet50()\n",
    "num_classes = 251\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load(\"Transfer_Learning/models/best_FineTuned_ResNet50_NO_FREEZE.pth\"))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "from utils.fine_tune_pytorch import eval_model_on_test_loader\n",
    "\n",
    "cm = eval_model_on_test_loader(model, \"finetuned_pretrained_ResNet50_ImageNet1k_classifier_test\", \"misc\", test, True, 5)\n",
    "testD = ImageDataset(datasets.TEST_DEGRADED,224,True)\n",
    "testD = DataLoader(testD,batch_size=1,shuffle=False)\n",
    "cm = eval_model_on_test_loader(model, \"finetuned_pretrained_ResNet50_ImageNet1k_classifier_test_degraded\", \"misc\", testD, True, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11994/11994 [02:30<00:00, 79.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 26.62164415541104 %\n",
      "5-Accuracy: 53.21827580456895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11994/11994 [02:31<00:00, 79.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 20.16008004002001 %\n",
      "5-Accuracy: 43.03818575954644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "test = ImageDataset(datasets.TEST,224,True)\n",
    "test = DataLoader(test,batch_size=1,shuffle=False)\n",
    "model = models.resnet50()\n",
    "num_classes = 251\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load(\"Transfer_Learning/models/best_FineTuned_ResNet50_NO_FREEZE_DEGRADED_DATA_HALF_LR.pth\"))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "from utils.fine_tune_pytorch import eval_model_on_test_loader\n",
    "\n",
    "cm = eval_model_on_test_loader(model, \"finetuned_pretrained_ResNet50_ImageNet1k_classifier_test\", \"misc\", test, True, 5)\n",
    "testD = ImageDataset(datasets.TEST_DEGRADED,224,True)\n",
    "testD = DataLoader(testD,batch_size=1,shuffle=False)\n",
    "cm = eval_model_on_test_loader(model, \"finetuned_pretrained_ResNet50_ImageNet1k_classifier_test_degraded\", \"misc\", testD, True, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
