{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: progettoVIPM\n"
     ]
    }
   ],
   "source": [
    "if(os.path.split(os.getcwd())[1] == \"misc\"):\n",
    "    os.chdir(\"..\")\n",
    "print(\"Current Working Directory: {}\".format(os.path.split(os.getcwd())[1]))\n",
    "\n",
    "cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.loadersAndEnums import datasets\n",
    "from utils.loadersAndEnums import networks\n",
    "from utils.loadersAndEnums import ImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VALIDATION SET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:06<00:00, 152.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.593625498007968 %\n",
      "5-Accuracy: 6.175298804780876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2), # 256x256x3 -> 256x256x32\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)) # 256x256x32 -> 128x128x32   \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2), # 128x128x32 -> 128x128x64\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)) # 128x128x64 -> 64x64x64\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2), # 64x64x64 -> 64x64x128\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)) # 64x64x128 -> 32x32x128\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(32*32*128, 500)\n",
    "        self.fc2 = nn.Linear(500, 251)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        out = nn.ReLU()(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "model=ConvNet()\n",
    "model.load_state_dict(torch.load('misc/models/best_baseline.pth'))\n",
    "from torch.utils.data import DataLoader\n",
    "val = ImageDataset(datasets.VALIDATION_LABELED_20,256,True)\n",
    "val = DataLoader(val,batch_size=1,shuffle=False)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "from utils.fine_tune_pytorch import eval_model_on_test_loader\n",
    "\n",
    "cm = eval_model_on_test_loader(model, \"Baseline_Validation\", \"misc\", val, True, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPARSE AUTOENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1004 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:04<00:00, 226.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.796812749003984 %\n",
      "5-Accuracy: 2.091633466135458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.sparseAutoencoder import SparseAutoencoderL1\n",
    "best_model_path = 'self-supervised/models/best_sparse_AE.pth'\n",
    "sparseAE = SparseAutoencoderL1()\n",
    "sparseAE.load_state_dict(torch.load(best_model_path))\n",
    "sparseAE.eval()  # Set the model to evaluation mode\n",
    "sparseAE.to(device)\n",
    "class ExtendedEncoderV2(nn.Module):\n",
    "    def __init__(self, base_encoder):\n",
    "        super(ExtendedEncoderV2, self).__init__()\n",
    "        self.base_encoder = base_encoder\n",
    "\n",
    "        # Additional convolutional and ReLU layers\n",
    "        self.additional_conv = nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.additional_relu = nn.ReLU()\n",
    "\n",
    "        # Dynamically compute flatten_dim\n",
    "        dummy_input = torch.randn(1, 3, 256, 256).to(device)  # Simulate input\n",
    "        self.additional_conv.to(device)  # Move additional_conv to the same device\n",
    "        dummy_output = self.base_encoder(dummy_input)  # Get encoder output\n",
    "        dummy_output = self.additional_conv(dummy_output)  # Pass through additional conv layer\n",
    "        dummy_output = self.additional_relu(dummy_output)  # Pass through additional ReLU layer\n",
    "        self.flatten_dim = dummy_output.view(1, -1).size(1)  # Flatten dimension\n",
    "\n",
    "        # Fully connected layers with dropout\n",
    "        self.fc1 = nn.Linear(self.flatten_dim, 260)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(260, 251)\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        # Freeze base encoder weights\n",
    "        for param in self.base_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_encoder(x)  # Base encoder\n",
    "        x = self.additional_conv(x)  # Additional conv layer\n",
    "        x = self.additional_relu(x)  # Additional ReLU layer\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc1(x)  # Fully connected layer\n",
    "        x = self.relu(x)  # ReLU activation\n",
    "        x = self.dropout1(x)  # Dropout\n",
    "        x = self.fc2(x)  # Fully connected layer\n",
    "        x = self.dropout2(x)  # Dropout\n",
    "        x = self.softmax(x)  # Softmax activation\n",
    "        return x\n",
    "    \n",
    "    \n",
    "from torch.utils.data import DataLoader\n",
    "val = ImageDataset(datasets.VALIDATION_LABELED_20,256,True)\n",
    "val = DataLoader(val,batch_size=1,shuffle=False)\n",
    "exEncoder = ExtendedEncoderV2(sparseAE.encoder)\n",
    "exEncoder.load_state_dict(torch.load(\"self-supervised/models/best_AE_classifier.pth\"))\n",
    "exEncoder.to(device)\n",
    "from utils.fine_tune_pytorch import eval_model_on_test_loader\n",
    "\n",
    "cm = eval_model_on_test_loader(exEncoder, \"sparse_encoder_classifier_validation\", \"misc\", val, True, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COLORIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:13<00:00, 73.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0956175298804782\n",
      "5-Accuracy: 3.386454183266932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "class ColorizationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ColorizationModel, self).__init__()\n",
    "        # Encoder: Convolutional layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Output size: 64 x 128 x 128\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # Output size: 128 x 64 x 64\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) # Output size: 256 x 32 x 32\n",
    "        )\n",
    "        # Decoder: Deconvolutional layers\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 2, kernel_size=4, stride=2, padding=1),  # Output 2 channels (a, b)\n",
    "            nn.Tanh()  # Normalize output to range [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        output = self.decoder(features)\n",
    "        return output\n",
    "    \n",
    "best_model_path = 'self-supervised/models/best_Colorizer.pth'\n",
    "\n",
    "colorizer = ColorizationModel()\n",
    "colorizer.load_state_dict(torch.load(best_model_path))\n",
    "colorizer.to(device)\n",
    "class ExtendedColorizerLinear(nn.Module):\n",
    "    def __init__(self, colorizer):\n",
    "        super(ExtendedColorizerLinear, self).__init__()\n",
    "        self.encoder = colorizer.encoder\n",
    "        self.ff1 = nn.Linear(256*32*32, 1024)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.ff2 = nn.Linear(1024, 251)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(-1, 256*32*32)\n",
    "        x = self.ff1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "exColorizer = ExtendedColorizerLinear(colorizer)\n",
    "\n",
    "best_model_path = 'self-supervised/models/best_LinearColorizer_classifier.pth'\n",
    "\n",
    "exColorizer.load_state_dict(torch.load(best_model_path))\n",
    "exColorizer.to(device)\n",
    "def process_batch(batch):\n",
    "    batch = batch.cpu().numpy()\n",
    "    batch = np.moveaxis(batch, 1, -1)  # Move channel axis to the end\n",
    "    lab_batch = np.array([cv2.cvtColor(img, cv2.COLOR_RGB2LAB) for img in batch])\n",
    "    \n",
    "    L_batch = lab_batch[:,:,:,0] / 255.0\n",
    "    ab_batch = lab_batch[:,:,:,1:] / 128.0\n",
    "    \n",
    "    L_batch = torch.tensor(L_batch, dtype=torch.float32).unsqueeze(1)  # Add channel dimension\n",
    "    ab_batch = torch.tensor(ab_batch, dtype=torch.float32).permute(0, 3, 1, 2)  # Move channel axis to the second position\n",
    "    \n",
    "    return L_batch, ab_batch\n",
    "\n",
    "k = 5\n",
    "k_correct = 0\n",
    "total = len(val)\n",
    "exColorizer.eval()\n",
    "predictions = np.zeros(len(val))\n",
    "# Disable gradient computation and reduce memory consumption.\n",
    "y_test = np.zeros(len(val))\n",
    "with torch.no_grad():\n",
    "    i = 0\n",
    "    for test_data in tqdm(val):\n",
    "        test_features, test_labels = test_data\n",
    "        test_features,_ = process_batch(test_features)\n",
    "        test_features = test_features.to(device)\n",
    "        y_test[i] = test_labels.cpu()\n",
    "        outputs = exColorizer(test_features)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions[i] = predicted.item()\n",
    "        _, indexes = torch.sort(outputs, descending=True)\n",
    "        indexes = indexes[0,0:k]\n",
    "        if y_test[i] in indexes:\n",
    "            k_correct += 1\n",
    "        i+=1\n",
    "\n",
    "k_accuracy = 100*(k_correct/total)\n",
    "accuracy = 100*accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: {}\".format(accuracy))\n",
    "print(\"{}-Accuracy: {}\".format(k, k_accuracy))\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm = np.array(cm)\n",
    "np.save(\"./{}/model_metrics/ConfM_{}.npy\".format(\"misc\", \"Linear_Colorizer_Classifier_validation\"), cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COLORIZER + DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:14<00:00, 71.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.49800796812749004\n",
      "5-Accuracy: 2.788844621513944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "class ColorizationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ColorizationModel, self).__init__()\n",
    "        # Encoder: Convolutional layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Output size: 64 x 128 x 128\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # Output size: 128 x 64 x 64\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) # Output size: 256 x 32 x 32\n",
    "        )\n",
    "        # Decoder: Deconvolutional layers\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 2, kernel_size=4, stride=2, padding=1),  # Output 2 channels (a, b)\n",
    "            nn.Tanh()  # Normalize output to range [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        output = self.decoder(features)\n",
    "        return output\n",
    "    \n",
    "best_model_path = 'self-supervised/models/best_Colorizer.pth'\n",
    "\n",
    "colorizer = ColorizationModel()\n",
    "colorizer.load_state_dict(torch.load(best_model_path))\n",
    "colorizer.to(device)\n",
    "class ExtendedColorizerLinear(nn.Module):\n",
    "    def __init__(self, colorizer):\n",
    "        super(ExtendedColorizerLinear, self).__init__()\n",
    "        self.encoder = colorizer.encoder\n",
    "        self.ff1 = nn.Linear(256*32*32, 1024)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.ff2 = nn.Linear(1024, 251)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(-1, 256*32*32)\n",
    "        x = self.ff1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "exColorizer = ExtendedColorizerLinear(colorizer)\n",
    "\n",
    "best_model_path = 'self-supervised/models/best_Augmented_LinearColorizer_classifier.pth'\n",
    "\n",
    "exColorizer.load_state_dict(torch.load(best_model_path))\n",
    "exColorizer.to(device)\n",
    "def process_batch(batch):\n",
    "    batch = batch.cpu().numpy()\n",
    "    batch = np.moveaxis(batch, 1, -1)  # Move channel axis to the end\n",
    "    lab_batch = np.array([cv2.cvtColor(img, cv2.COLOR_RGB2LAB) for img in batch])\n",
    "    \n",
    "    L_batch = lab_batch[:,:,:,0] / 255.0\n",
    "    ab_batch = lab_batch[:,:,:,1:] / 128.0\n",
    "    \n",
    "    L_batch = torch.tensor(L_batch, dtype=torch.float32).unsqueeze(1)  # Add channel dimension\n",
    "    ab_batch = torch.tensor(ab_batch, dtype=torch.float32).permute(0, 3, 1, 2)  # Move channel axis to the second position\n",
    "    \n",
    "    return L_batch, ab_batch\n",
    "\n",
    "k = 5\n",
    "k_correct = 0\n",
    "total = len(val)\n",
    "exColorizer.eval()\n",
    "predictions = np.zeros(len(val))\n",
    "# Disable gradient computation and reduce memory consumption.\n",
    "y_test = np.zeros(len(val))\n",
    "with torch.no_grad():\n",
    "    i = 0\n",
    "    for test_data in tqdm(val):\n",
    "        test_features, test_labels = test_data\n",
    "        test_features,_ = process_batch(test_features)\n",
    "        test_features = test_features.to(device)\n",
    "        y_test[i] = test_labels.cpu()\n",
    "        outputs = exColorizer(test_features)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions[i] = predicted.item()\n",
    "        _, indexes = torch.sort(outputs, descending=True)\n",
    "        indexes = indexes[0,0:k]\n",
    "        if y_test[i] in indexes:\n",
    "            k_correct += 1\n",
    "        i+=1\n",
    "\n",
    "k_accuracy = 100*(k_correct/total)\n",
    "accuracy = 100*accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: {}\".format(accuracy))\n",
    "print(\"{}-Accuracy: {}\".format(k, k_accuracy))\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm = np.array(cm)\n",
    "np.save(\"./{}/model_metrics/ConfM_{}.npy\".format(\"misc\", \"Augmented_Linear_Colorizer_Classifier_validation\"), cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COLORIZER + LABELS CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:13<00:00, 72.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.398406374501992\n",
      "5-Accuracy: 2.49003984063745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "class ColorizationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ColorizationModel, self).__init__()\n",
    "        # Encoder: Convolutional layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Output size: 64 x 128 x 128\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # Output size: 128 x 64 x 64\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) # Output size: 256 x 32 x 32\n",
    "        )\n",
    "        # Decoder: Deconvolutional layers\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 2, kernel_size=4, stride=2, padding=1),  # Output 2 channels (a, b)\n",
    "            nn.Tanh()  # Normalize output to range [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        output = self.decoder(features)\n",
    "        return output\n",
    "    \n",
    "best_model_path = 'self-supervised/models/best_Colorizer.pth'\n",
    "\n",
    "colorizer = ColorizationModel()\n",
    "colorizer.load_state_dict(torch.load(best_model_path))\n",
    "colorizer.to(device)\n",
    "class ExtendedColorizerLinear(nn.Module):\n",
    "    def __init__(self, colorizer):\n",
    "        super(ExtendedColorizerLinear, self).__init__()\n",
    "        self.encoder = colorizer.encoder\n",
    "        self.ff1 = nn.Linear(256*32*32, 1024)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.ff2 = nn.Linear(1024, 251)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(-1, 256*32*32)\n",
    "        x = self.ff1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "exColorizer = ExtendedColorizerLinear(colorizer)\n",
    "\n",
    "best_model_path = 'self-supervised/models/best_Label_Extended_LinearColorizer_classifier.pth'\n",
    "\n",
    "exColorizer.load_state_dict(torch.load(best_model_path))\n",
    "exColorizer.to(device)\n",
    "def process_batch(batch):\n",
    "    batch = batch.cpu().numpy()\n",
    "    batch = np.moveaxis(batch, 1, -1)  # Move channel axis to the end\n",
    "    lab_batch = np.array([cv2.cvtColor(img, cv2.COLOR_RGB2LAB) for img in batch])\n",
    "    \n",
    "    L_batch = lab_batch[:,:,:,0] / 255.0\n",
    "    ab_batch = lab_batch[:,:,:,1:] / 128.0\n",
    "    \n",
    "    L_batch = torch.tensor(L_batch, dtype=torch.float32).unsqueeze(1)  # Add channel dimension\n",
    "    ab_batch = torch.tensor(ab_batch, dtype=torch.float32).permute(0, 3, 1, 2)  # Move channel axis to the second position\n",
    "    \n",
    "    return L_batch, ab_batch\n",
    "\n",
    "k = 5\n",
    "k_correct = 0\n",
    "total = len(val)\n",
    "exColorizer.eval()\n",
    "predictions = np.zeros(len(val))\n",
    "# Disable gradient computation and reduce memory consumption.\n",
    "y_test = np.zeros(len(val))\n",
    "with torch.no_grad():\n",
    "    i = 0\n",
    "    for test_data in tqdm(val):\n",
    "        test_features, test_labels = test_data\n",
    "        test_features,_ = process_batch(test_features)\n",
    "        test_features = test_features.to(device)\n",
    "        y_test[i] = test_labels.cpu()\n",
    "        outputs = exColorizer(test_features)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions[i] = predicted.item()\n",
    "        _, indexes = torch.sort(outputs, descending=True)\n",
    "        indexes = indexes[0,0:k]\n",
    "        if y_test[i] in indexes:\n",
    "            k_correct += 1\n",
    "        i+=1\n",
    "\n",
    "k_accuracy = 100*(k_correct/total)\n",
    "accuracy = 100*accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: {}\".format(accuracy))\n",
    "print(\"{}-Accuracy: {}\".format(k, k_accuracy))\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm = np.array(cm)\n",
    "np.save(\"./{}/model_metrics/ConfM_{}.npy\".format(\"misc\", \"Label_Extended_Linear_Colorizer_Classifier_validation\"), cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRETRAINED RESNET 50 (FOOD101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:11<00:00, 90.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 32.669322709163346 %\n",
      "5-Accuracy: 59.26294820717132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "val = ImageDataset(datasets.VALIDATION_LABELED_20,224,True)\n",
    "val = DataLoader(val,batch_size=1,shuffle=False)\n",
    "model = models.resnet50()\n",
    "num_classes = 251\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load(\"Transfer_Learning/models/best_FineTuned_ResNet50.pth\"))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "from utils.fine_tune_pytorch import eval_model_on_test_loader\n",
    "\n",
    "cm = eval_model_on_test_loader(model, \"Finetuned_FOOD101_ResNet50_validation\", \"misc\", val, True, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRETRAINED RESNET 50 (IMAGENET1K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:10<00:00, 92.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 25.39840637450199 %\n",
      "5-Accuracy: 49.40239043824701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "num_classes = 251\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load(\"Transfer_Learning/models/best_FineTuned_ResNet50_NO_FREEZE.pth\"))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "from torch.utils.data import DataLoader\n",
    "val = ImageDataset(datasets.VALIDATION_LABELED_20,224,True)\n",
    "val = DataLoader(val,batch_size=1,shuffle=False)\n",
    "from utils.fine_tune_pytorch import eval_model_on_test_loader\n",
    "cm = eval_model_on_test_loader(model, \"Finetuned_IMAGENET1K_ResNet50_validation\", \"misc\", val, True, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASSIFY TO LEARN RESNET 50 (FOOD101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:03<00:00, 278.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.29880478087649404 %\n",
      "5-Accuracy: 1.693227091633466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "data = np.fromfile('misc/models/all_out_from_resnet_5080.dat')\n",
    "\n",
    "val = ImageDataset(datasets.VALIDATION_LABELED_20,224,True)\n",
    "val = DataLoader(val,batch_size=1,shuffle=False)\n",
    "k = 5\n",
    "k_correct = 0\n",
    "total = len(val)\n",
    "predictions = np.zeros(len(val))\n",
    "# Disable gradient computation and reduce memory consumption.\n",
    "y_test = np.zeros(len(val))\n",
    "\n",
    "i = 0\n",
    "for test_data in tqdm(val):\n",
    "    test_features, test_labels = test_data\n",
    "    y_test[i] = test_labels.cpu()\n",
    "    outputs = torch.tensor(data[i*251:i*251+251], device=device).unsqueeze(0)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    predictions[i] = predicted.item()\n",
    "    _, indexes = torch.sort(outputs, descending=True)\n",
    "    indexes = indexes[0, :k]\n",
    "    if y_test[i] in indexes:\n",
    "        k_correct += 1\n",
    "    i+=1\n",
    "\n",
    "k_accuracy = 100*(k_correct/total)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: {} %\".format(accuracy *100))\n",
    "print(\"{}-Accuracy: {}\".format(k, k_accuracy))\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm = np.array(cm)\n",
    "np.save(\"./{}/model_metrics/ConfM_{}.npy\".format(\"misc\", \"classify_to_learn_extended_Finetuned_ResNet50_validation\"), cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(251,)\n"
     ]
    }
   ],
   "source": [
    "print(data[i:i+251].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRETRAINED RESNET50(IMAGENET1K) AUGMENTED TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:10<00:00, 94.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 22.808764940239044 %\n",
      "5-Accuracy: 46.31474103585657\n",
      "DEGRADED VALIDATION:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:11<00:00, 90.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 16.235059760956176 %\n",
      "5-Accuracy: 35.55776892430279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "val = ImageDataset(datasets.VALIDATION_20,224,True)\n",
    "val = DataLoader(val,batch_size=1,shuffle=False)\n",
    "model = models.resnet50()\n",
    "num_classes = 251\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load(\"Transfer_Learning/models/best_FineTuned_ResNet50_NO_FREEZE_DEGRADED_DATA_HALF_LR.pth\"))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "from utils.fine_tune_pytorch import eval_model_on_test_loader\n",
    "print(\"VALIDATION:\")\n",
    "cm = eval_model_on_test_loader(model, \"Finetuned_IMAGENET1K_ResNet50_Data_Augmentation_PyTorch_Weights_validation_\", \"misc\", val, True, 5)\n",
    "valD = ImageDataset(datasets.VALIDATION_20_DEGRADED,224,True)\n",
    "valD = DataLoader(valD,batch_size=1,shuffle=False)\n",
    "print(\"DEGRADED VALIDATION:\")\n",
    "cm = eval_model_on_test_loader(model, \"Finetuned_IMAGENET1K_ResNet50_Data_Augmentation_PyTorch_Weights_validation_degraded\", \"misc\", valD, True, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:11<00:00, 88.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 26.195219123505975 %\n",
      "5-Accuracy: 52.788844621513945\n",
      "DEGRADED VALIDATION:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:11<00:00, 86.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 18.92430278884462 %\n",
      "5-Accuracy: 36.05577689243028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "val = ImageDataset(datasets.VALIDATION_20,224,True)\n",
    "val = DataLoader(val,batch_size=1,shuffle=False)\n",
    "model = models.resnet50()\n",
    "num_classes = 251\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load(\"Transfer_Learning/models/best_FineTuned_ResNet50_NO_FREEZE_DEGRADED_DATA_ALREADY_FINETUNED.pth\"))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "from utils.fine_tune_pytorch import eval_model_on_test_loader\n",
    "print(\"VALIDATION:\")\n",
    "cm = eval_model_on_test_loader(model, \"Finetuned_IMAGENET1K_ResNet50_Data_Augmentation_Finetuned_Weights_validation_\", \"misc\", val, True, 5)\n",
    "valD = ImageDataset(datasets.VALIDATION_20_DEGRADED,224,True)\n",
    "valD = DataLoader(valD,batch_size=1,shuffle=False)\n",
    "print(\"DEGRADED VALIDATION:\")\n",
    "cm = eval_model_on_test_loader(model, \"Finetuned_IMAGENET1K_ResNet50_Data_Augmentation_Finetuned_Weights_validation_degraded\", \"misc\", valD, True, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRETRAINED RESNET50 (FOOD101) AUGMENTED TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ORIGINAL WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:11<00:00, 88.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 28.984063745019924 %\n",
      "5-Accuracy: 54.482071713147405\n",
      "DEGRADED VALIDATION:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:11<00:00, 89.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 24.40239043824701 %\n",
      "5-Accuracy: 47.808764940239044\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "val = ImageDataset(datasets.VALIDATION_20,224,True)\n",
    "val = DataLoader(val,batch_size=1,shuffle=False)\n",
    "model = models.resnet50()\n",
    "num_classes = 251\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = torch.load(\"Transfer_Learning/models/finetunedResNet50_minusnessuno_10e_64bsize_80_20_split_dataset_degraded_train_whole.pth\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "from utils.fine_tune_pytorch import eval_model_on_test_loader\n",
    "print(\"VALIDATION:\")\n",
    "cm = eval_model_on_test_loader(model, \"Finetuned_FOOD101_ResNet50_Data_Augmentation_Origina_Weights_validation_\", \"misc\", val, True, 5)\n",
    "valD = ImageDataset(datasets.VALIDATION_20_DEGRADED,224,True)\n",
    "valD = DataLoader(valD,batch_size=1,shuffle=False)\n",
    "print(\"DEGRADED VALIDATION:\")\n",
    "cm = eval_model_on_test_loader(model, \"Finetuned_FOOD101_ResNet50_Data_Augmentation_Origina_Weights_validation_degraded\", \"misc\", valD, True, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINETUNED WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:11<00:00, 86.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 28.286852589641438 %\n",
      "5-Accuracy: 51.79282868525896\n",
      "DEGRADED VALIDATION:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:11<00:00, 86.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 23.107569721115535 %\n",
      "5-Accuracy: 45.41832669322709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "val = ImageDataset(datasets.VALIDATION_20,224,True)\n",
    "val = DataLoader(val,batch_size=1,shuffle=False)\n",
    "model = models.resnet50()\n",
    "num_classes = 251\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = torch.load(\"Transfer_Learning/models/10e_64bsize_80_20_split_dataset_degraded_from_previous_weights.pth\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "from utils.fine_tune_pytorch import eval_model_on_test_loader\n",
    "print(\"VALIDATION:\")\n",
    "cm = eval_model_on_test_loader(model, \"Finetuned_FOOD101_ResNet50_Data_Augmentation_Finetuned_Weights_validation_\", \"misc\", val, True, 5)\n",
    "valD = ImageDataset(datasets.VALIDATION_20_DEGRADED,224,True)\n",
    "valD = DataLoader(valD,batch_size=1,shuffle=False)\n",
    "print(\"DEGRADED VALIDATION:\")\n",
    "cm = eval_model_on_test_loader(model, \"Finetuned_FOOD101_ResNet50_Data_Augmentation_Finetuned_Weights_validation_degraded\", \"misc\", valD, True, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST SETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRETRAINED RESNET50 (FOOD101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B.: Results are in order: TEST, TEST_DEGRADED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11994/11994 [02:13<00:00, 89.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 39.73653493413373\n",
      "5-Accuracy: 67.60046690011673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11994/11994 [02:13<00:00, 89.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 26.721694180423544\n",
      "5-Accuracy: 48.79939969984993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "test = ImageDataset(datasets.TEST,224,True)\n",
    "test = DataLoader(test,batch_size=1,shuffle=False)\n",
    "model = models.resnet50()\n",
    "num_classes = 251\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load(\"Transfer_Learning/models/best_FineTuned_ResNet50.pth\"))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "from utils.fine_tune_pytorch import eval_model_on_test_loader\n",
    "\n",
    "cm = eval_model_on_test_loader(model, \"finetuned_pretrained_ResNet50_Food101_classifier_test\", \"misc\", test, True, 5)\n",
    "testD = ImageDataset(datasets.TEST_DEGRADED,224,True)\n",
    "testD = DataLoader(testD,batch_size=1,shuffle=False)\n",
    "cm = eval_model_on_test_loader(model, \"finetuned_pretrained_ResNet50_Food101_classifier_test_degraded\", \"misc\", testD, True, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRETRAINED RESNET50 (IMAGENET1K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11994/11994 [02:06<00:00, 95.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 29.87326996831749\n",
      "5-Accuracy: 55.61113890278473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11994/11994 [02:05<00:00, 95.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 18.325829581457395\n",
      "5-Accuracy: 36.87677171919293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "test = ImageDataset(datasets.TEST,224,True)\n",
    "test = DataLoader(test,batch_size=1,shuffle=False)\n",
    "model = models.resnet50()\n",
    "num_classes = 251\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load(\"Transfer_Learning/models/best_FineTuned_ResNet50_NO_FREEZE.pth\"))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "from utils.fine_tune_pytorch import eval_model_on_test_loader\n",
    "\n",
    "cm = eval_model_on_test_loader(model, \"finetuned_pretrained_ResNet50_ImageNet1k_classifier_test\", \"misc\", test, True, 5)\n",
    "testD = ImageDataset(datasets.TEST_DEGRADED,224,True)\n",
    "testD = DataLoader(testD,batch_size=1,shuffle=False)\n",
    "cm = eval_model_on_test_loader(model, \"finetuned_pretrained_ResNet50_ImageNet1k_classifier_test_degraded\", \"misc\", testD, True, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRETRAINED RESNET50(IMAGENET1K) AUGMENTED TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PYTORCH WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11994/11994 [02:30<00:00, 79.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 26.62164415541104 %\n",
      "5-Accuracy: 53.21827580456895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11994/11994 [02:31<00:00, 79.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 20.16008004002001 %\n",
      "5-Accuracy: 43.03818575954644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "test = ImageDataset(datasets.TEST,224,True)\n",
    "test = DataLoader(test,batch_size=1,shuffle=False)\n",
    "model = models.resnet50()\n",
    "num_classes = 251\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load(\"Transfer_Learning/models/best_FineTuned_ResNet50_NO_FREEZE_DEGRADED_DATA_HALF_LR.pth\"))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "from utils.fine_tune_pytorch import eval_model_on_test_loader\n",
    "\n",
    "cm = eval_model_on_test_loader(model, \"finetuned_pretrained_ResNet50_ImageNet1k_classifier_test\", \"misc\", test, True, 5)\n",
    "testD = ImageDataset(datasets.TEST_DEGRADED,224,True)\n",
    "testD = DataLoader(testD,batch_size=1,shuffle=False)\n",
    "cm = eval_model_on_test_loader(model, \"finetuned_pretrained_ResNet50_ImageNet1k_classifier_test_degraded\", \"misc\", testD, True, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRETRAINED RESNET50(FOOD101) AUGMENTED TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11994/11994 [02:25<00:00, 82.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 35.05919626479906 %\n",
      "5-Accuracy: 62.673003168250794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11994/11994 [02:18<00:00, 86.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 29.214607303651825 %\n",
      "5-Accuracy: 54.98582624645656\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "test = ImageDataset(datasets.TEST,224,True)\n",
    "test = DataLoader(test,batch_size=1,shuffle=False)\n",
    "model = models.resnet50()\n",
    "num_classes = 251\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = torch.load(\"Transfer_Learning/models/finetunedResNet50_minusnessuno_10e_64bsize_80_20_split_dataset_degraded_train_whole.pth\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "from utils.fine_tune_pytorch import eval_model_on_test_loader\n",
    "\n",
    "cm = eval_model_on_test_loader(model, \"finetuned_pretrained_ResNet50_ImageNet1k_classifier_test\", \"misc\", test, True, 5)\n",
    "testD = ImageDataset(datasets.TEST_DEGRADED,224,True)\n",
    "testD = DataLoader(testD,batch_size=1,shuffle=False)\n",
    "cm = eval_model_on_test_loader(model, \"finetuned_pretrained_ResNet50_ImageNet1k_classifier_test_degraded\", \"misc\", testD, True, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRETRAINED RESNET50(FOOD101) AUGMENTED TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINED WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11994/11994 [02:16<00:00, 87.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 32.98315824578956 %\n",
      "5-Accuracy: 60.2551275637819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11994/11994 [02:19<00:00, 85.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 26.62164415541104 %\n",
      "5-Accuracy: 51.77588794397199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "test = ImageDataset(datasets.TEST,224,True)\n",
    "test = DataLoader(test,batch_size=1,shuffle=False)\n",
    "model = models.resnet50()\n",
    "num_classes = 251\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = torch.load(\"Transfer_Learning/models/10e_64bsize_80_20_split_dataset_degraded_from_previous_weights.pth\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "from utils.fine_tune_pytorch import eval_model_on_test_loader\n",
    "\n",
    "cm = eval_model_on_test_loader(model, \"finetuned_pretrained_ResNet50_ImageNet1k_classifier_test\", \"misc\", test, True, 5)\n",
    "testD = ImageDataset(datasets.TEST_DEGRADED,224,True)\n",
    "testD = DataLoader(testD,batch_size=1,shuffle=False)\n",
    "cm = eval_model_on_test_loader(model, \"finetuned_pretrained_ResNet50_ImageNet1k_classifier_test_degraded\", \"misc\", testD, True, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
