{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: progettoVIPM\n"
     ]
    }
   ],
   "source": [
    "if(os.path.split(os.getcwd())[1] == \"misc\"):\n",
    "    os.chdir(\"..\")\n",
    "print(\"Current Working Directory: {}\".format(os.path.split(os.getcwd())[1]))\n",
    "\n",
    "cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.loadersAndEnums import datasets\n",
    "from utils.loadersAndEnums import networks\n",
    "from utils.loadersAndEnums import ImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VALIDATION SET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:06<00:00, 152.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.593625498007968 %\n",
      "5-Accuracy: 6.175298804780876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2), # 256x256x3 -> 256x256x32\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)) # 256x256x32 -> 128x128x32   \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2), # 128x128x32 -> 128x128x64\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)) # 128x128x64 -> 64x64x64\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2), # 64x64x64 -> 64x64x128\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)) # 64x64x128 -> 32x32x128\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(32*32*128, 500)\n",
    "        self.fc2 = nn.Linear(500, 251)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        out = nn.ReLU()(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "model=ConvNet()\n",
    "model.load_state_dict(torch.load('misc/models/best_baseline.pth'))\n",
    "from torch.utils.data import DataLoader\n",
    "val = ImageDataset(datasets.VALIDATION_LABELED_20,256,True)\n",
    "val = DataLoader(val,batch_size=1,shuffle=False)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "from utils.fine_tune_pytorch import eval_model_on_test_loader\n",
    "\n",
    "cm = eval_model_on_test_loader(model, \"Baseline_Validation\", \"misc\", val, True, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPARSE AUTOENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1004 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:04<00:00, 226.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.796812749003984 %\n",
      "5-Accuracy: 2.091633466135458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.sparseAutoencoder import SparseAutoencoderL1\n",
    "best_model_path = 'self-supervised/models/best_sparse_AE.pth'\n",
    "sparseAE = SparseAutoencoderL1()\n",
    "sparseAE.load_state_dict(torch.load(best_model_path))\n",
    "sparseAE.eval()  # Set the model to evaluation mode\n",
    "sparseAE.to(device)\n",
    "class ExtendedEncoderV2(nn.Module):\n",
    "    def __init__(self, base_encoder):\n",
    "        super(ExtendedEncoderV2, self).__init__()\n",
    "        self.base_encoder = base_encoder\n",
    "\n",
    "        # Additional convolutional and ReLU layers\n",
    "        self.additional_conv = nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.additional_relu = nn.ReLU()\n",
    "\n",
    "        # Dynamically compute flatten_dim\n",
    "        dummy_input = torch.randn(1, 3, 256, 256).to(device)  # Simulate input\n",
    "        self.additional_conv.to(device)  # Move additional_conv to the same device\n",
    "        dummy_output = self.base_encoder(dummy_input)  # Get encoder output\n",
    "        dummy_output = self.additional_conv(dummy_output)  # Pass through additional conv layer\n",
    "        dummy_output = self.additional_relu(dummy_output)  # Pass through additional ReLU layer\n",
    "        self.flatten_dim = dummy_output.view(1, -1).size(1)  # Flatten dimension\n",
    "\n",
    "        # Fully connected layers with dropout\n",
    "        self.fc1 = nn.Linear(self.flatten_dim, 260)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(260, 251)\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        # Freeze base encoder weights\n",
    "        for param in self.base_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_encoder(x)  # Base encoder\n",
    "        x = self.additional_conv(x)  # Additional conv layer\n",
    "        x = self.additional_relu(x)  # Additional ReLU layer\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc1(x)  # Fully connected layer\n",
    "        x = self.relu(x)  # ReLU activation\n",
    "        x = self.dropout1(x)  # Dropout\n",
    "        x = self.fc2(x)  # Fully connected layer\n",
    "        x = self.dropout2(x)  # Dropout\n",
    "        x = self.softmax(x)  # Softmax activation\n",
    "        return x\n",
    "    \n",
    "    \n",
    "from torch.utils.data import DataLoader\n",
    "val = ImageDataset(datasets.VALIDATION_LABELED_20,256,True)\n",
    "val = DataLoader(val,batch_size=1,shuffle=False)\n",
    "exEncoder = ExtendedEncoderV2(sparseAE.encoder)\n",
    "exEncoder.load_state_dict(torch.load(\"self-supervised/models/best_AE_classifier.pth\"))\n",
    "exEncoder.to(device)\n",
    "from utils.fine_tune_pytorch import eval_model_on_test_loader\n",
    "\n",
    "cm = eval_model_on_test_loader(exEncoder, \"sparse_encoder_classifier_validation\", \"misc\", val, True, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COLORIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:13<00:00, 73.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0956175298804782\n",
      "5-Accuracy: 3.386454183266932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "class ColorizationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ColorizationModel, self).__init__()\n",
    "        # Encoder: Convolutional layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Output size: 64 x 128 x 128\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # Output size: 128 x 64 x 64\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) # Output size: 256 x 32 x 32\n",
    "        )\n",
    "        # Decoder: Deconvolutional layers\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 2, kernel_size=4, stride=2, padding=1),  # Output 2 channels (a, b)\n",
    "            nn.Tanh()  # Normalize output to range [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        output = self.decoder(features)\n",
    "        return output\n",
    "    \n",
    "best_model_path = 'self-supervised/models/best_Colorizer.pth'\n",
    "\n",
    "colorizer = ColorizationModel()\n",
    "colorizer.load_state_dict(torch.load(best_model_path))\n",
    "colorizer.to(device)\n",
    "class ExtendedColorizerLinear(nn.Module):\n",
    "    def __init__(self, colorizer):\n",
    "        super(ExtendedColorizerLinear, self).__init__()\n",
    "        self.encoder = colorizer.encoder\n",
    "        self.ff1 = nn.Linear(256*32*32, 1024)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.ff2 = nn.Linear(1024, 251)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(-1, 256*32*32)\n",
    "        x = self.ff1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "exColorizer = ExtendedColorizerLinear(colorizer)\n",
    "\n",
    "best_model_path = 'self-supervised/models/best_LinearColorizer_classifier.pth'\n",
    "\n",
    "exColorizer.load_state_dict(torch.load(best_model_path))\n",
    "exColorizer.to(device)\n",
    "def process_batch(batch):\n",
    "    batch = batch.cpu().numpy()\n",
    "    batch = np.moveaxis(batch, 1, -1)  # Move channel axis to the end\n",
    "    lab_batch = np.array([cv2.cvtColor(img, cv2.COLOR_RGB2LAB) for img in batch])\n",
    "    \n",
    "    L_batch = lab_batch[:,:,:,0] / 255.0\n",
    "    ab_batch = lab_batch[:,:,:,1:] / 128.0\n",
    "    \n",
    "    L_batch = torch.tensor(L_batch, dtype=torch.float32).unsqueeze(1)  # Add channel dimension\n",
    "    ab_batch = torch.tensor(ab_batch, dtype=torch.float32).permute(0, 3, 1, 2)  # Move channel axis to the second position\n",
    "    \n",
    "    return L_batch, ab_batch\n",
    "\n",
    "k = 5\n",
    "k_correct = 0\n",
    "total = len(val)\n",
    "exColorizer.eval()\n",
    "predictions = np.zeros(len(val))\n",
    "# Disable gradient computation and reduce memory consumption.\n",
    "y_test = np.zeros(len(val))\n",
    "with torch.no_grad():\n",
    "    i = 0\n",
    "    for test_data in tqdm(val):\n",
    "        test_features, test_labels = test_data\n",
    "        test_features,_ = process_batch(test_features)\n",
    "        test_features = test_features.to(device)\n",
    "        y_test[i] = test_labels.cpu()\n",
    "        outputs = exColorizer(test_features)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions[i] = predicted.item()\n",
    "        _, indexes = torch.sort(outputs, descending=True)\n",
    "        indexes = indexes[0,0:k]\n",
    "        if y_test[i] in indexes:\n",
    "            k_correct += 1\n",
    "        i+=1\n",
    "\n",
    "k_accuracy = 100*(k_correct/total)\n",
    "accuracy = 100*accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: {}\".format(accuracy))\n",
    "print(\"{}-Accuracy: {}\".format(k, k_accuracy))\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm = np.array(cm)\n",
    "np.save(\"./{}/model_metrics/ConfM_{}.npy\".format(\"misc\", \"Linear_Colorizer_Classifier_validation\"), cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COLORIZER + DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:14<00:00, 71.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.49800796812749004\n",
      "5-Accuracy: 2.788844621513944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "class ColorizationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ColorizationModel, self).__init__()\n",
    "        # Encoder: Convolutional layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Output size: 64 x 128 x 128\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # Output size: 128 x 64 x 64\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) # Output size: 256 x 32 x 32\n",
    "        )\n",
    "        # Decoder: Deconvolutional layers\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 2, kernel_size=4, stride=2, padding=1),  # Output 2 channels (a, b)\n",
    "            nn.Tanh()  # Normalize output to range [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        output = self.decoder(features)\n",
    "        return output\n",
    "    \n",
    "best_model_path = 'self-supervised/models/best_Colorizer.pth'\n",
    "\n",
    "colorizer = ColorizationModel()\n",
    "colorizer.load_state_dict(torch.load(best_model_path))\n",
    "colorizer.to(device)\n",
    "class ExtendedColorizerLinear(nn.Module):\n",
    "    def __init__(self, colorizer):\n",
    "        super(ExtendedColorizerLinear, self).__init__()\n",
    "        self.encoder = colorizer.encoder\n",
    "        self.ff1 = nn.Linear(256*32*32, 1024)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.ff2 = nn.Linear(1024, 251)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(-1, 256*32*32)\n",
    "        x = self.ff1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "exColorizer = ExtendedColorizerLinear(colorizer)\n",
    "\n",
    "best_model_path = 'self-supervised/models/best_Augmented_LinearColorizer_classifier.pth'\n",
    "\n",
    "exColorizer.load_state_dict(torch.load(best_model_path))\n",
    "exColorizer.to(device)\n",
    "def process_batch(batch):\n",
    "    batch = batch.cpu().numpy()\n",
    "    batch = np.moveaxis(batch, 1, -1)  # Move channel axis to the end\n",
    "    lab_batch = np.array([cv2.cvtColor(img, cv2.COLOR_RGB2LAB) for img in batch])\n",
    "    \n",
    "    L_batch = lab_batch[:,:,:,0] / 255.0\n",
    "    ab_batch = lab_batch[:,:,:,1:] / 128.0\n",
    "    \n",
    "    L_batch = torch.tensor(L_batch, dtype=torch.float32).unsqueeze(1)  # Add channel dimension\n",
    "    ab_batch = torch.tensor(ab_batch, dtype=torch.float32).permute(0, 3, 1, 2)  # Move channel axis to the second position\n",
    "    \n",
    "    return L_batch, ab_batch\n",
    "\n",
    "k = 5\n",
    "k_correct = 0\n",
    "total = len(val)\n",
    "exColorizer.eval()\n",
    "predictions = np.zeros(len(val))\n",
    "# Disable gradient computation and reduce memory consumption.\n",
    "y_test = np.zeros(len(val))\n",
    "with torch.no_grad():\n",
    "    i = 0\n",
    "    for test_data in tqdm(val):\n",
    "        test_features, test_labels = test_data\n",
    "        test_features,_ = process_batch(test_features)\n",
    "        test_features = test_features.to(device)\n",
    "        y_test[i] = test_labels.cpu()\n",
    "        outputs = exColorizer(test_features)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions[i] = predicted.item()\n",
    "        _, indexes = torch.sort(outputs, descending=True)\n",
    "        indexes = indexes[0,0:k]\n",
    "        if y_test[i] in indexes:\n",
    "            k_correct += 1\n",
    "        i+=1\n",
    "\n",
    "k_accuracy = 100*(k_correct/total)\n",
    "accuracy = 100*accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: {}\".format(accuracy))\n",
    "print(\"{}-Accuracy: {}\".format(k, k_accuracy))\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm = np.array(cm)\n",
    "np.save(\"./{}/model_metrics/ConfM_{}.npy\".format(\"misc\", \"Augmented_Linear_Colorizer_Classifier_validation\"), cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COLORIZER + LABELS CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:13<00:00, 72.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.398406374501992\n",
      "5-Accuracy: 2.49003984063745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "class ColorizationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ColorizationModel, self).__init__()\n",
    "        # Encoder: Convolutional layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Output size: 64 x 128 x 128\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # Output size: 128 x 64 x 64\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) # Output size: 256 x 32 x 32\n",
    "        )\n",
    "        # Decoder: Deconvolutional layers\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 2, kernel_size=4, stride=2, padding=1),  # Output 2 channels (a, b)\n",
    "            nn.Tanh()  # Normalize output to range [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        output = self.decoder(features)\n",
    "        return output\n",
    "    \n",
    "best_model_path = 'self-supervised/models/best_Colorizer.pth'\n",
    "\n",
    "colorizer = ColorizationModel()\n",
    "colorizer.load_state_dict(torch.load(best_model_path))\n",
    "colorizer.to(device)\n",
    "class ExtendedColorizerLinear(nn.Module):\n",
    "    def __init__(self, colorizer):\n",
    "        super(ExtendedColorizerLinear, self).__init__()\n",
    "        self.encoder = colorizer.encoder\n",
    "        self.ff1 = nn.Linear(256*32*32, 1024)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.ff2 = nn.Linear(1024, 251)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(-1, 256*32*32)\n",
    "        x = self.ff1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "exColorizer = ExtendedColorizerLinear(colorizer)\n",
    "\n",
    "best_model_path = 'self-supervised/models/best_Label_Extended_LinearColorizer_classifier.pth'\n",
    "\n",
    "exColorizer.load_state_dict(torch.load(best_model_path))\n",
    "exColorizer.to(device)\n",
    "def process_batch(batch):\n",
    "    batch = batch.cpu().numpy()\n",
    "    batch = np.moveaxis(batch, 1, -1)  # Move channel axis to the end\n",
    "    lab_batch = np.array([cv2.cvtColor(img, cv2.COLOR_RGB2LAB) for img in batch])\n",
    "    \n",
    "    L_batch = lab_batch[:,:,:,0] / 255.0\n",
    "    ab_batch = lab_batch[:,:,:,1:] / 128.0\n",
    "    \n",
    "    L_batch = torch.tensor(L_batch, dtype=torch.float32).unsqueeze(1)  # Add channel dimension\n",
    "    ab_batch = torch.tensor(ab_batch, dtype=torch.float32).permute(0, 3, 1, 2)  # Move channel axis to the second position\n",
    "    \n",
    "    return L_batch, ab_batch\n",
    "\n",
    "k = 5\n",
    "k_correct = 0\n",
    "total = len(val)\n",
    "exColorizer.eval()\n",
    "predictions = np.zeros(len(val))\n",
    "# Disable gradient computation and reduce memory consumption.\n",
    "y_test = np.zeros(len(val))\n",
    "with torch.no_grad():\n",
    "    i = 0\n",
    "    for test_data in tqdm(val):\n",
    "        test_features, test_labels = test_data\n",
    "        test_features,_ = process_batch(test_features)\n",
    "        test_features = test_features.to(device)\n",
    "        y_test[i] = test_labels.cpu()\n",
    "        outputs = exColorizer(test_features)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions[i] = predicted.item()\n",
    "        _, indexes = torch.sort(outputs, descending=True)\n",
    "        indexes = indexes[0,0:k]\n",
    "        if y_test[i] in indexes:\n",
    "            k_correct += 1\n",
    "        i+=1\n",
    "\n",
    "k_accuracy = 100*(k_correct/total)\n",
    "accuracy = 100*accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: {}\".format(accuracy))\n",
    "print(\"{}-Accuracy: {}\".format(k, k_accuracy))\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm = np.array(cm)\n",
    "np.save(\"./{}/model_metrics/ConfM_{}.npy\".format(\"misc\", \"Label_Extended_Linear_Colorizer_Classifier_validation\"), cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRETRAINED RESNET 50 (FOOD101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:11<00:00, 90.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 32.669322709163346 %\n",
      "5-Accuracy: 59.26294820717132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "val = ImageDataset(datasets.VALIDATION_LABELED_20,224,True)\n",
    "val = DataLoader(val,batch_size=1,shuffle=False)\n",
    "model = models.resnet50()\n",
    "num_classes = 251\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load(\"Transfer_Learning/models/best_FineTuned_ResNet50.pth\"))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "from utils.fine_tune_pytorch import eval_model_on_test_loader\n",
    "\n",
    "cm = eval_model_on_test_loader(model, \"Finetuned_FOOD101_ResNet50_validation\", \"misc\", val, True, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRETRAINED RESNET 50 (IMAGENET1K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:10<00:00, 92.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 25.39840637450199 %\n",
      "5-Accuracy: 49.40239043824701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "num_classes = 251\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load(\"Transfer_Learning/models/best_FineTuned_ResNet50_NO_FREEZE.pth\"))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "from torch.utils.data import DataLoader\n",
    "val = ImageDataset(datasets.VALIDATION_LABELED_20,224,True)\n",
    "val = DataLoader(val,batch_size=1,shuffle=False)\n",
    "from utils.fine_tune_pytorch import eval_model_on_test_loader\n",
    "cm = eval_model_on_test_loader(model, \"Finetuned_IMAGENET1K_ResNet50_validation\", \"misc\", val, True, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASSIFY TO LEARN RESNET 50 (FOOD101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:03<00:00, 278.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.29880478087649404 %\n",
      "5-Accuracy: 1.693227091633466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "data = np.fromfile('misc/models/all_out_from_resnet_5080.dat')\n",
    "\n",
    "val = ImageDataset(datasets.VALIDATION_LABELED_20,224,True)\n",
    "val = DataLoader(val,batch_size=1,shuffle=False)\n",
    "k = 5\n",
    "k_correct = 0\n",
    "total = len(val)\n",
    "predictions = np.zeros(len(val))\n",
    "# Disable gradient computation and reduce memory consumption.\n",
    "y_test = np.zeros(len(val))\n",
    "\n",
    "i = 0\n",
    "for test_data in tqdm(val):\n",
    "    test_features, test_labels = test_data\n",
    "    y_test[i] = test_labels.cpu()\n",
    "    outputs = torch.tensor(data[i*251:i*251+251], device=device).unsqueeze(0)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    predictions[i] = predicted.item()\n",
    "    _, indexes = torch.sort(outputs, descending=True)\n",
    "    indexes = indexes[0, :k]\n",
    "    if y_test[i] in indexes:\n",
    "        k_correct += 1\n",
    "    i+=1\n",
    "\n",
    "k_accuracy = 100*(k_correct/total)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: {} %\".format(accuracy *100))\n",
    "print(\"{}-Accuracy: {}\".format(k, k_accuracy))\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm = np.array(cm)\n",
    "np.save(\"./{}/model_metrics/ConfM_{}.npy\".format(\"misc\", \"classify_to_learn_extended_Finetuned_ResNet50_validation\"), cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(251,)\n"
     ]
    }
   ],
   "source": [
    "print(data[i:i+251].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRETRAINED RESNET50(IMAGENET1K) AUGMENTED TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:10<00:00, 94.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 22.808764940239044 %\n",
      "5-Accuracy: 46.31474103585657\n",
      "DEGRADED VALIDATION:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:11<00:00, 90.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 16.235059760956176 %\n",
      "5-Accuracy: 35.55776892430279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "val = ImageDataset(datasets.VALIDATION_20,224,True)\n",
    "val = DataLoader(val,batch_size=1,shuffle=False)\n",
    "model = models.resnet50()\n",
    "num_classes = 251\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load(\"Transfer_Learning/models/best_FineTuned_ResNet50_NO_FREEZE_DEGRADED_DATA_HALF_LR.pth\"))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "from utils.fine_tune_pytorch import eval_model_on_test_loader\n",
    "print(\"VALIDATION:\")\n",
    "cm = eval_model_on_test_loader(model, \"Finetuned_IMAGENET1K_ResNet50_Data_Augmentation_PyTorch_Weights_validation_\", \"misc\", val, True, 5)\n",
    "valD = ImageDataset(datasets.VALIDATION_20_DEGRADED,224,True)\n",
    "valD = DataLoader(valD,batch_size=1,shuffle=False)\n",
    "print(\"DEGRADED VALIDATION:\")\n",
    "cm = eval_model_on_test_loader(model, \"Finetuned_IMAGENET1K_ResNet50_Data_Augmentation_PyTorch_Weights_validation_degraded\", \"misc\", valD, True, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:11<00:00, 88.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 26.195219123505975 %\n",
      "5-Accuracy: 52.788844621513945\n",
      "DEGRADED VALIDATION:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:11<00:00, 86.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 18.92430278884462 %\n",
      "5-Accuracy: 36.05577689243028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "val = ImageDataset(datasets.VALIDATION_20,224,True)\n",
    "val = DataLoader(val,batch_size=1,shuffle=False)\n",
    "model = models.resnet50()\n",
    "num_classes = 251\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load(\"Transfer_Learning/models/best_FineTuned_ResNet50_NO_FREEZE_DEGRADED_DATA_ALREADY_FINETUNED.pth\"))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "from utils.fine_tune_pytorch import eval_model_on_test_loader\n",
    "print(\"VALIDATION:\")\n",
    "cm = eval_model_on_test_loader(model, \"Finetuned_IMAGENET1K_ResNet50_Data_Augmentation_Finetuned_Weights_validation_\", \"misc\", val, True, 5)\n",
    "valD = ImageDataset(datasets.VALIDATION_20_DEGRADED,224,True)\n",
    "valD = DataLoader(valD,batch_size=1,shuffle=False)\n",
    "print(\"DEGRADED VALIDATION:\")\n",
    "cm = eval_model_on_test_loader(model, \"Finetuned_IMAGENET1K_ResNet50_Data_Augmentation_Finetuned_Weights_validation_degraded\", \"misc\", valD, True, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRETRAINED RESNET50 (FOOD101) AUGMENTED TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ORIGINAL WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:11<00:00, 88.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 28.984063745019924 %\n",
      "5-Accuracy: 54.482071713147405\n",
      "DEGRADED VALIDATION:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:11<00:00, 89.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 24.40239043824701 %\n",
      "5-Accuracy: 47.808764940239044\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "val = ImageDataset(datasets.VALIDATION_20,224,True)\n",
    "val = DataLoader(val,batch_size=1,shuffle=False)\n",
    "model = models.resnet50()\n",
    "num_classes = 251\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = torch.load(\"Transfer_Learning/models/finetunedResNet50_minusnessuno_10e_64bsize_80_20_split_dataset_degraded_train_whole.pth\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "from utils.fine_tune_pytorch import eval_model_on_test_loader\n",
    "print(\"VALIDATION:\")\n",
    "cm = eval_model_on_test_loader(model, \"Finetuned_FOOD101_ResNet50_Data_Augmentation_Origina_Weights_validation_\", \"misc\", val, True, 5)\n",
    "valD = ImageDataset(datasets.VALIDATION_20_DEGRADED,224,True)\n",
    "valD = DataLoader(valD,batch_size=1,shuffle=False)\n",
    "print(\"DEGRADED VALIDATION:\")\n",
    "cm = eval_model_on_test_loader(model, \"Finetuned_FOOD101_ResNet50_Data_Augmentation_Origina_Weights_validation_degraded\", \"misc\", valD, True, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINETUNED WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:11<00:00, 86.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 28.286852589641438 %\n",
      "5-Accuracy: 51.79282868525896\n",
      "DEGRADED VALIDATION:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:11<00:00, 86.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 23.107569721115535 %\n",
      "5-Accuracy: 45.41832669322709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "val = ImageDataset(datasets.VALIDATION_20,224,True)\n",
    "val = DataLoader(val,batch_size=1,shuffle=False)\n",
    "model = models.resnet50()\n",
    "num_classes = 251\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = torch.load(\"Transfer_Learning/models/10e_64bsize_80_20_split_dataset_degraded_from_previous_weights.pth\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "from utils.fine_tune_pytorch import eval_model_on_test_loader\n",
    "print(\"VALIDATION:\")\n",
    "cm = eval_model_on_test_loader(model, \"Finetuned_FOOD101_ResNet50_Data_Augmentation_Finetuned_Weights_validation_\", \"misc\", val, True, 5)\n",
    "valD = ImageDataset(datasets.VALIDATION_20_DEGRADED,224,True)\n",
    "valD = DataLoader(valD,batch_size=1,shuffle=False)\n",
    "print(\"DEGRADED VALIDATION:\")\n",
    "cm = eval_model_on_test_loader(model, \"Finetuned_FOOD101_ResNet50_Data_Augmentation_Finetuned_Weights_validation_degraded\", \"misc\", valD, True, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST SETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRETRAINED RESNET50 (FOOD101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B.: Results are in order: TEST, TEST_DEGRADED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11994/11994 [02:30<00:00, 79.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 39.73653493413373 %\n",
      "5-Accuracy: 67.60046690011673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11994/11994 [02:23<00:00, 83.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 26.721694180423544 %\n",
      "5-Accuracy: 48.79939969984993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "test = ImageDataset(datasets.TEST,224,True)\n",
    "test = DataLoader(test,batch_size=1,shuffle=False)\n",
    "model = models.resnet50()\n",
    "num_classes = 251\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load(\"Transfer_Learning/models/best_FineTuned_ResNet50.pth\"))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "from utils.fine_tune_pytorch import eval_model_on_test_loader\n",
    "\n",
    "cm = eval_model_on_test_loader(model, \"finetuned_pretrained_ResNet50_Food101_classifier_test\", \"misc\", test, True, 5)\n",
    "testD = ImageDataset(datasets.TEST_DEGRADED,224,True)\n",
    "testD = DataLoader(testD,batch_size=1,shuffle=False)\n",
    "cm = eval_model_on_test_loader(model, \"finetuned_pretrained_ResNet50_Food101_classifier_test_degraded\", \"misc\", testD, True, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRETRAINED RESNET50 (IMAGENET1K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11994/11994 [02:25<00:00, 82.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 29.87326996831749 %\n",
      "5-Accuracy: 55.61113890278473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11994/11994 [02:16<00:00, 87.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 18.325829581457395 %\n",
      "5-Accuracy: 36.87677171919293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "test = ImageDataset(datasets.TEST,224,True)\n",
    "test = DataLoader(test,batch_size=1,shuffle=False)\n",
    "model = models.resnet50()\n",
    "num_classes = 251\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load(\"Transfer_Learning/models/best_FineTuned_ResNet50_NO_FREEZE.pth\"))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "from utils.fine_tune_pytorch import eval_model_on_test_loader\n",
    "\n",
    "cm = eval_model_on_test_loader(model, \"finetuned_pretrained_ResNet50_ImageNet1k_classifier_test\", \"misc\", test, True, 5)\n",
    "testD = ImageDataset(datasets.TEST_DEGRADED,224,True)\n",
    "testD = DataLoader(testD,batch_size=1,shuffle=False)\n",
    "cm = eval_model_on_test_loader(model, \"finetuned_pretrained_ResNet50_ImageNet1k_classifier_test_degraded\", \"misc\", testD, True, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRETRAINED RESNET50(FOOD101) AUGMENTED TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11994/11994 [02:18<00:00, 86.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 35.05919626479906 %\n",
      "5-Accuracy: 62.673003168250794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11994/11994 [02:23<00:00, 83.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 29.214607303651825 %\n",
      "5-Accuracy: 54.98582624645656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "test = ImageDataset(datasets.TEST,224,True)\n",
    "test = DataLoader(test,batch_size=1,shuffle=False)\n",
    "model = models.resnet50()\n",
    "num_classes = 251\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = torch.load(\"Transfer_Learning/models/finetunedResNet50_minusnessuno_10e_64bsize_80_20_split_dataset_degraded_train_whole.pth\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "from utils.fine_tune_pytorch import eval_model_on_test_loader\n",
    "\n",
    "cm = eval_model_on_test_loader(model, \"Finetuned_FOOD101_ResNet50_Data_Augmentation_Origina_Weights_test_\", \"misc\", test, True, 5)\n",
    "testD = ImageDataset(datasets.TEST_DEGRADED,224,True)\n",
    "testD = DataLoader(testD,batch_size=1,shuffle=False)\n",
    "cm = eval_model_on_test_loader(model, \"Finetuned_FOOD101_ResNet50_Data_Augmentation_Origina_Weights_test_degraded\", \"misc\", testD, True, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_validation = {}\n",
    "top5_accuracy_validation = {}\n",
    "accuracy_test = {}\n",
    "top5_accuracy_test = {}\n",
    "accuracy_validation_degraded = {}\n",
    "top5_accuracy_validation_degraded = {}\n",
    "accuracy_test_degraded = {}\n",
    "top5_accuracy_test_degraded = {}\n",
    "accuracy_validation[\"Baseline\"] = 1.593625498007968\n",
    "top5_accuracy_validation[\"Baseline\"] = 6.175298804780876\n",
    "accuracy_validation[\"Sparse Autoencoder\"] = 0.796812749003984\n",
    "top5_accuracy_validation[\"Sparse Autoencoder\"] = 2.091633466135458\n",
    "accuracy_validation[\"Colorizer\"] = 1.0956175298804782\n",
    "top5_accuracy_validation[\"Colorizer\"] = 3.386454183266932\n",
    "accuracy_validation[\"Colorizer + Data Augmentation\"] = 0.49800796812749004\n",
    "top5_accuracy_validation[\"Colorizer + Data Augmentation\"] = 2.788844621513944\n",
    "accuracy_validation[\"Colorizer + Labels Clustering\"] = 0.398406374501992\n",
    "top5_accuracy_validation[\"Colorizer + Labels Clustering\"] = 2.49003984063745\n",
    "accuracy_validation[\"Pretrained ResNet50 (FOOD101)\"] = 32.669322709163346\n",
    "top5_accuracy_validation[\"Pretrained ResNet50 (FOOD101)\"] = 59.26294820717132\n",
    "accuracy_validation[\"Pretrained ResNet50 (ImageNet1k)\"] = 25.39840637450199\n",
    "top5_accuracy_validation[\"Pretrained ResNet50 (ImageNet1k)\"] = 49.40239043824701\n",
    "accuracy_validation[\"Classify To Learn ResNet50\"] = 0.29880478087649404\n",
    "top5_accuracy_validation[\"Classify To Learn ResNet50\"] = 1.693227091633466\n",
    "accuracy_validation[\"Pretrained ResNet50 (ImageNet1k) Augmented Training Pytorch Weights\"] = 22.808764940239044\n",
    "top5_accuracy_validation[\"Pretrained ResNet50 (ImageNet1k) Augmented Training Pytorch Weights\"] =  46.31474103585657\n",
    "accuracy_validation_degraded[\"Pretrained ResNet50 (ImageNet1k) Augmented Training Pytorch Weights\"] = 16.235059760956176\n",
    "top5_accuracy_validation_degraded[\"Pretrained ResNet50 (ImageNet1k) Augmented Training Pytorch Weights\"] =  35.55776892430279\n",
    "accuracy_validation[\"Pretrained ResNet50 (ImageNet1k) Augmented Training Trained Weights\"] = 26.195219123505975\n",
    "top5_accuracy_validation[\"Pretrained ResNet50 (ImageNet1k) Augmented Training Trained Weights\"] = 52.788844621513945\n",
    "accuracy_validation_degraded[\"Pretrained ResNet50 (ImageNet1k) Augmented Training Trained Weights\"] = 18.92430278884462\n",
    "top5_accuracy_test_degraded[\"Pretrained ResNet50 (ImageNet1k) Augmented Training Trained Weights\"] =  36.05577689243028\n",
    "accuracy_validation[\"Pretrained ResNet50 (FOOD101) Augmented Training Original Weights\"] = 28.984063745019924\n",
    "top5_accuracy_validation[\"Pretrained ResNet50 (FOOD101) Augmented Training Original Weights\"] =  54.482071713147405\n",
    "accuracy_validation_degraded[\"Pretrained ResNet50 (FOOD101) Augmented Training Original Weights\"] = 24.40239043824701\n",
    "top5_accuracy_validation_degraded[\"Pretrained ResNet50 (FOOD101) Augmented Training Original Weights\"] =  47.808764940239044\n",
    "accuracy_validation[\"Pretrained ResNet50 (FOOD101) Augmented Training Trained Weights\"] = 28.286852589641438\n",
    "top5_accuracy_validation[\"Pretrained ResNet50 (FOOD101) Augmented Training Trained Weights\"] =  51.79282868525896\n",
    "accuracy_validation_degraded[\"Pretrained ResNet50 (FOOD101) Augmented Training Trained Weights\"] = 23.107569721115535\n",
    "top5_accuracy_validation_degraded[\"Pretrained ResNet50 (FOOD101) Augmented Training Trained Weights\"] =  45.41832669322709\n",
    "accuracy_test[\"Pretrained ResNet50 (FOOD101)\"] = 39.73653493413373\n",
    "top5_accuracy_test[\"Pretrained ResNet50 (FOOD101)\"] = 67.60046690011673\n",
    "accuracy_test_degraded[\"Pretrained ResNet50 (FOOD101)\"] = 26.721694180423544\n",
    "top5_accuracy_test_degraded[\"Pretrained ResNet50 (FOOD101)\"] =  48.79939969984993\n",
    "accuracy_test[\"Pretrained ResNet50 (ImageNet1k)\"] = 29.87326996831749\n",
    "top5_accuracy_test[\"Pretrained ResNet50 (ImageNet1k)\"] =  55.61113890278473\n",
    "accuracy_test_degraded[\"Pretrained ResNet50 (ImageNet1k)\"] = 18.325829581457395\n",
    "top5_accuracy_test_degraded[\"Pretrained ResNet50 (ImageNet1k)\"] =  36.87677171919293\n",
    "accuracy_test[\"Pretrained ResNet50 (FOOD101) Augmented Training Original Weights\"] = 27.69418042354049\n",
    "top5_accuracy_test[\"Pretrained ResNet50 (FOOD101) Augmented Training Original Weights\"] =  62.673003168250794\n",
    "accuracy_test_degraded[\"Pretrained ResNet50 (FOOD101) Augmented Training Original Weights\"] = 29.214607303651825\n",
    "top5_accuracy_test_degraded[\"Pretrained ResNet50 (FOOD101) Augmented Training Original Weights\"] =  54.98582624645656\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marco\\AppData\\Local\\Temp\\ipykernel_12372\\310768856.py:19: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'N/A' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.fillna(\"N/A\", inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_validation</th>\n",
       "      <th>top5_accuracy_validation</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>top5_accuracy_test</th>\n",
       "      <th>accuracy_validation_degraded</th>\n",
       "      <th>top5_accuracy_validation_degraded</th>\n",
       "      <th>accuracy_test_degraded</th>\n",
       "      <th>top5_accuracy_test_degraded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Classify To Learn ResNet50</th>\n",
       "      <td>0.298805</td>\n",
       "      <td>1.693227</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colorizer + Labels Clustering</th>\n",
       "      <td>0.398406</td>\n",
       "      <td>2.490040</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colorizer + Data Augmentation</th>\n",
       "      <td>0.498008</td>\n",
       "      <td>2.788845</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sparse Autoencoder</th>\n",
       "      <td>0.796813</td>\n",
       "      <td>2.091633</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colorizer</th>\n",
       "      <td>1.095618</td>\n",
       "      <td>3.386454</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>1.593625</td>\n",
       "      <td>6.175299</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pretrained ResNet50 (ImageNet1k) Augmented Training Pytorch Weights</th>\n",
       "      <td>22.808765</td>\n",
       "      <td>46.314741</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>16.23506</td>\n",
       "      <td>35.557769</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pretrained ResNet50 (ImageNet1k)</th>\n",
       "      <td>25.398406</td>\n",
       "      <td>49.402390</td>\n",
       "      <td>29.87327</td>\n",
       "      <td>55.611139</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>18.32583</td>\n",
       "      <td>36.876772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pretrained ResNet50 (ImageNet1k) Augmented Training Trained Weights</th>\n",
       "      <td>26.195219</td>\n",
       "      <td>52.788845</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>18.924303</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>36.055777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pretrained ResNet50 (FOOD101) Augmented Training Trained Weights</th>\n",
       "      <td>28.286853</td>\n",
       "      <td>51.792829</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>23.10757</td>\n",
       "      <td>45.418327</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pretrained ResNet50 (FOOD101) Augmented Training Original Weights</th>\n",
       "      <td>28.984064</td>\n",
       "      <td>54.482072</td>\n",
       "      <td>27.69418</td>\n",
       "      <td>62.673003</td>\n",
       "      <td>24.40239</td>\n",
       "      <td>47.808765</td>\n",
       "      <td>29.214607</td>\n",
       "      <td>54.985826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pretrained ResNet50 (FOOD101)</th>\n",
       "      <td>32.669323</td>\n",
       "      <td>59.262948</td>\n",
       "      <td>39.736535</td>\n",
       "      <td>67.600467</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>26.721694</td>\n",
       "      <td>48.7994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    accuracy_validation  \\\n",
       "Classify To Learn ResNet50                                     0.298805   \n",
       "Colorizer + Labels Clustering                                  0.398406   \n",
       "Colorizer + Data Augmentation                                  0.498008   \n",
       "Sparse Autoencoder                                             0.796813   \n",
       "Colorizer                                                      1.095618   \n",
       "Baseline                                                       1.593625   \n",
       "Pretrained ResNet50 (ImageNet1k) Augmented Trai...            22.808765   \n",
       "Pretrained ResNet50 (ImageNet1k)                              25.398406   \n",
       "Pretrained ResNet50 (ImageNet1k) Augmented Trai...            26.195219   \n",
       "Pretrained ResNet50 (FOOD101) Augmented Trainin...            28.286853   \n",
       "Pretrained ResNet50 (FOOD101) Augmented Trainin...            28.984064   \n",
       "Pretrained ResNet50 (FOOD101)                                 32.669323   \n",
       "\n",
       "                                                    top5_accuracy_validation  \\\n",
       "Classify To Learn ResNet50                                          1.693227   \n",
       "Colorizer + Labels Clustering                                       2.490040   \n",
       "Colorizer + Data Augmentation                                       2.788845   \n",
       "Sparse Autoencoder                                                  2.091633   \n",
       "Colorizer                                                           3.386454   \n",
       "Baseline                                                            6.175299   \n",
       "Pretrained ResNet50 (ImageNet1k) Augmented Trai...                 46.314741   \n",
       "Pretrained ResNet50 (ImageNet1k)                                   49.402390   \n",
       "Pretrained ResNet50 (ImageNet1k) Augmented Trai...                 52.788845   \n",
       "Pretrained ResNet50 (FOOD101) Augmented Trainin...                 51.792829   \n",
       "Pretrained ResNet50 (FOOD101) Augmented Trainin...                 54.482072   \n",
       "Pretrained ResNet50 (FOOD101)                                      59.262948   \n",
       "\n",
       "                                                   accuracy_test  \\\n",
       "Classify To Learn ResNet50                                   N/A   \n",
       "Colorizer + Labels Clustering                                N/A   \n",
       "Colorizer + Data Augmentation                                N/A   \n",
       "Sparse Autoencoder                                           N/A   \n",
       "Colorizer                                                    N/A   \n",
       "Baseline                                                     N/A   \n",
       "Pretrained ResNet50 (ImageNet1k) Augmented Trai...           N/A   \n",
       "Pretrained ResNet50 (ImageNet1k)                        29.87327   \n",
       "Pretrained ResNet50 (ImageNet1k) Augmented Trai...           N/A   \n",
       "Pretrained ResNet50 (FOOD101) Augmented Trainin...           N/A   \n",
       "Pretrained ResNet50 (FOOD101) Augmented Trainin...      27.69418   \n",
       "Pretrained ResNet50 (FOOD101)                          39.736535   \n",
       "\n",
       "                                                   top5_accuracy_test  \\\n",
       "Classify To Learn ResNet50                                        N/A   \n",
       "Colorizer + Labels Clustering                                     N/A   \n",
       "Colorizer + Data Augmentation                                     N/A   \n",
       "Sparse Autoencoder                                                N/A   \n",
       "Colorizer                                                         N/A   \n",
       "Baseline                                                          N/A   \n",
       "Pretrained ResNet50 (ImageNet1k) Augmented Trai...                N/A   \n",
       "Pretrained ResNet50 (ImageNet1k)                            55.611139   \n",
       "Pretrained ResNet50 (ImageNet1k) Augmented Trai...                N/A   \n",
       "Pretrained ResNet50 (FOOD101) Augmented Trainin...                N/A   \n",
       "Pretrained ResNet50 (FOOD101) Augmented Trainin...          62.673003   \n",
       "Pretrained ResNet50 (FOOD101)                               67.600467   \n",
       "\n",
       "                                                   accuracy_validation_degraded  \\\n",
       "Classify To Learn ResNet50                                                  N/A   \n",
       "Colorizer + Labels Clustering                                               N/A   \n",
       "Colorizer + Data Augmentation                                               N/A   \n",
       "Sparse Autoencoder                                                          N/A   \n",
       "Colorizer                                                                   N/A   \n",
       "Baseline                                                                    N/A   \n",
       "Pretrained ResNet50 (ImageNet1k) Augmented Trai...                     16.23506   \n",
       "Pretrained ResNet50 (ImageNet1k)                                            N/A   \n",
       "Pretrained ResNet50 (ImageNet1k) Augmented Trai...                    18.924303   \n",
       "Pretrained ResNet50 (FOOD101) Augmented Trainin...                     23.10757   \n",
       "Pretrained ResNet50 (FOOD101) Augmented Trainin...                     24.40239   \n",
       "Pretrained ResNet50 (FOOD101)                                               N/A   \n",
       "\n",
       "                                                   top5_accuracy_validation_degraded  \\\n",
       "Classify To Learn ResNet50                                                       N/A   \n",
       "Colorizer + Labels Clustering                                                    N/A   \n",
       "Colorizer + Data Augmentation                                                    N/A   \n",
       "Sparse Autoencoder                                                               N/A   \n",
       "Colorizer                                                                        N/A   \n",
       "Baseline                                                                         N/A   \n",
       "Pretrained ResNet50 (ImageNet1k) Augmented Trai...                         35.557769   \n",
       "Pretrained ResNet50 (ImageNet1k)                                                 N/A   \n",
       "Pretrained ResNet50 (ImageNet1k) Augmented Trai...                               N/A   \n",
       "Pretrained ResNet50 (FOOD101) Augmented Trainin...                         45.418327   \n",
       "Pretrained ResNet50 (FOOD101) Augmented Trainin...                         47.808765   \n",
       "Pretrained ResNet50 (FOOD101)                                                    N/A   \n",
       "\n",
       "                                                   accuracy_test_degraded  \\\n",
       "Classify To Learn ResNet50                                            N/A   \n",
       "Colorizer + Labels Clustering                                         N/A   \n",
       "Colorizer + Data Augmentation                                         N/A   \n",
       "Sparse Autoencoder                                                    N/A   \n",
       "Colorizer                                                             N/A   \n",
       "Baseline                                                              N/A   \n",
       "Pretrained ResNet50 (ImageNet1k) Augmented Trai...                    N/A   \n",
       "Pretrained ResNet50 (ImageNet1k)                                 18.32583   \n",
       "Pretrained ResNet50 (ImageNet1k) Augmented Trai...                    N/A   \n",
       "Pretrained ResNet50 (FOOD101) Augmented Trainin...                    N/A   \n",
       "Pretrained ResNet50 (FOOD101) Augmented Trainin...              29.214607   \n",
       "Pretrained ResNet50 (FOOD101)                                   26.721694   \n",
       "\n",
       "                                                   top5_accuracy_test_degraded  \n",
       "Classify To Learn ResNet50                                                 N/A  \n",
       "Colorizer + Labels Clustering                                              N/A  \n",
       "Colorizer + Data Augmentation                                              N/A  \n",
       "Sparse Autoencoder                                                         N/A  \n",
       "Colorizer                                                                  N/A  \n",
       "Baseline                                                                   N/A  \n",
       "Pretrained ResNet50 (ImageNet1k) Augmented Trai...                         N/A  \n",
       "Pretrained ResNet50 (ImageNet1k)                                     36.876772  \n",
       "Pretrained ResNet50 (ImageNet1k) Augmented Trai...                   36.055777  \n",
       "Pretrained ResNet50 (FOOD101) Augmented Trainin...                         N/A  \n",
       "Pretrained ResNet50 (FOOD101) Augmented Trainin...                   54.985826  \n",
       "Pretrained ResNet50 (FOOD101)                                          48.7994  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert dictionaries to Pandas Series\n",
    "import pandas as pd\n",
    "\n",
    "dicts = {\n",
    "    \"accuracy_validation\": accuracy_validation,\n",
    "    \"top5_accuracy_validation\": top5_accuracy_validation,\n",
    "    \"accuracy_test\": accuracy_test,\n",
    "    \"top5_accuracy_test\": top5_accuracy_test,\n",
    "    \"accuracy_validation_degraded\": accuracy_validation_degraded,\n",
    "    \"top5_accuracy_validation_degraded\": top5_accuracy_validation_degraded,\n",
    "    \"accuracy_test_degraded\": accuracy_test_degraded,\n",
    "    \"top5_accuracy_test_degraded\": top5_accuracy_test_degraded\n",
    "}\n",
    "\n",
    "# Create a DataFrame by concatenating the Series\n",
    "df = pd.DataFrame({name: pd.Series(data) for name, data in dicts.items()})\n",
    "\n",
    "# Fill NaN values with a placeholder (optional)\n",
    "df.fillna(\"N/A\", inplace=True)\n",
    "df.sort_values(by=\"accuracy_validation\", ascending=True, inplace=True)\n",
    "\n",
    "# Display DataFrame\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"misc/model_metrics/metrics.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
