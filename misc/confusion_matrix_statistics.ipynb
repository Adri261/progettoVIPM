{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: progettoVIPM\n"
     ]
    }
   ],
   "source": [
    "if(os.path.split(os.getcwd())[1] == \"misc\"):\n",
    "    os.chdir(\"..\")\n",
    "print(\"Current Working Directory: {}\".format(os.path.split(os.getcwd())[1]))\n",
    "\n",
    "cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "_TYPES = Literal[\"highest\", \"lowest\"]\n",
    "\n",
    "class Confusion_Matrix_stats():\n",
    "    def __init__(self, filename, classes):\n",
    "        \n",
    "        # Load the data from file\n",
    "\n",
    "        self.filename = filename\n",
    "\n",
    "        if \".npy\" in filename:\n",
    "            print(\"File is readable by numpy\")\n",
    "            self.cm = np.load(filename).astype(\"float32\")\n",
    "        if \".csv\" in filename:\n",
    "            print(\"File is readable by csv\")\n",
    "            self.cm = np.loadtxt(filename, delimiter=\",\", dtype=np.int64)\n",
    "        \n",
    "        \n",
    "        self.classes = classes\n",
    "\n",
    "        # Compute basic metrics\n",
    "\n",
    "        self.accuracy = self.cm.diagonal()/self.cm.sum(axis=1)\n",
    "\n",
    "        self.total_accuracy = self.cm.diagonal().sum() / self.cm.sum()\n",
    "\n",
    "        self.best_class = [self.classes[np.unravel_index(np.argmax(self.cm.diagonal(), axis=None), self.cm.diagonal().shape)], \n",
    "                            np.max(self.cm.diagonal(), axis=None),\n",
    "                            self.cm[np.unravel_index(np.argmax(self.cm.diagonal(), axis=None), self.cm.diagonal().shape)].sum()]\n",
    "\n",
    "        self.worst_class = [self.classes[np.unravel_index(np.argmin(self.cm.diagonal(), axis=None), self.cm.diagonal().shape)], \n",
    "                            np.min(self.cm.diagonal(), axis=None),\n",
    "                            self.cm[np.unravel_index(np.argmin(self.cm.diagonal(), axis=None), self.cm.diagonal().shape)].sum()]\n",
    "        \n",
    "        # the following matrix is used to compute both the false negative and false positives by using dot prodct\n",
    "        # the values will be retrieved from the diagonal of the obtained matrix\n",
    "        prod_matrix = np.ones(self.cm.shape, dtype=np.int8)\n",
    "        np.fill_diagonal(prod_matrix, 0)\n",
    "\n",
    "        self.false_negative = np.dot(self.cm, prod_matrix).diagonal()\n",
    "\n",
    "        self.false_positive = np.dot(np.transpose(self.cm), prod_matrix).diagonal()\n",
    "\n",
    "        self.true_positive = self.cm.diagonal()\n",
    "\n",
    "        self.real_positive = np.sum(self.cm, axis=1)\n",
    "\n",
    "        self.real_negative = np.sum(self.cm, axis=0)\n",
    "\n",
    "        # the true negative values are computed by excluding the rest of the values from the total sum of the matrix\n",
    "\n",
    "        self.true_negative = -self.real_negative + self.cm.sum() - self.real_positive + self.true_positive\n",
    "\n",
    "        self.predicted_positive = self.true_positive + self.false_positive\n",
    "\n",
    "        self.predicted_negative = self.false_negative + self.true_negative\n",
    "\n",
    "        # Compute advanced metrics\n",
    "\n",
    "        self.precision = self.true_positive / self.predicted_positive\n",
    "\n",
    "        self.recall = self.true_positive/self.real_positive\n",
    "\n",
    "        self.f1 = 2*(self.precision * self.recall)/(self.precision + self.recall)\n",
    "\n",
    "    def show_top_k_confused_classes(self, k):\n",
    "        # This function returns the top k confused classes as a list of double values\n",
    "        # the returned list is bicriterional in the sense that it returns the top k confused classes in both ways.\n",
    "        # As an example: if the couple (1,2) is returned it means that the total amount of cases in which 1 was confused with 2\n",
    "        # and vice versa was great\n",
    "\n",
    "        \n",
    "        # The following matrix \"summed_mat\" is initialized, it will eventually contain\n",
    "        # the sums of the rows and columns of the confusion mat of each class\n",
    "        # This is basically accomplished by summing the upper triangular part of the matrix with the lower triangular part\n",
    "        # the height of the matrix is set as self.cm.shape[0]-1 because we do self.cm.shape[0]-1 iterations\n",
    "        # since at every iteration the remaining parts of the matrix to confront shrinks when the last row\n",
    "        # is reached there will be no confront to make\n",
    "        summed_mat = np.zeros((self.cm.shape[0]-1, self.cm.shape[1]), dtype=np.int64)\n",
    "        for i in range(self.cm.shape[0]-1):\n",
    "            # sum the errors in the row and column relative to the current class i\n",
    "            i_row = self.cm[i, i+1:]\n",
    "            i_column = self.cm[i+1:, i]\n",
    "            i_row = i_row + i_column\n",
    "            # there is a padding of -1s in order to obtain a vector of correct lenght.\n",
    "            # -1 are chosen because when doing argmax operation they will never be chosen, since in self.cm the minimum value is 0\n",
    "            i_row = np.pad(i_row, (i+1,0), 'constant', constant_values=(-1))\n",
    "            summed_mat[i] = i_row\n",
    "        top_k= []\n",
    "        print(\"These are the top k confused couples of classes\")\n",
    "        for i in range(k):\n",
    "            # unravel_index is needed because np.argmax returns the position of the maximum value in the flattened array\n",
    "            pos = np.unravel_index(np.argmax(summed_mat, axis=None), summed_mat.shape)\n",
    "            p = (self.classes[pos[0]], self.classes[pos[1]])\n",
    "            print(\"#{}: {}; has been confused {} times\".format(i+1, p, np.max(summed_mat)))\n",
    "            top_k.append(pos)\n",
    "            # after printing ad appending the couple we set the value at its position as -1 in order to not choose it again\n",
    "            summed_mat[pos]=-1\n",
    "        return top_k\n",
    "\n",
    "\n",
    "\n",
    "    def show_metrics(self, index):\n",
    "        \n",
    "        print(\"---------------------------------------------------------\")\n",
    "        print(\"Showing metrics of class: {}; filename:{}\".format(self.classes[index], self.filename))\n",
    "        print(\"Total accuracy of given cm: {} %\".format(self.total_accuracy * 100))\n",
    "        print(\"Best class: {}; {}/{}\".format(self.best_class[0], int(self.best_class[1]), int(self.best_class[2])))\n",
    "        print(\"Worst class: {}; {}/{}\".format(self.worst_class[0], int(self.worst_class[1]), int(self.worst_class[2])))\n",
    "        print(\"-------------------basic metrics------------------------\")\n",
    "\n",
    "        print(\"Accuracy: {} %\".format(self.accuracy[index] * 100))\n",
    "\n",
    "        print(\"N° of real positives: {}\".format(self.real_positive[index]))\n",
    "        print(\"N° of true positives: {}\".format(self.true_positive[index]))\n",
    "        print(\"N° of false negatives: {}\".format(self.false_negative[index]))\n",
    "\n",
    "        print(\"N° of real negatives: {}\".format(self.real_negative[index]))\n",
    "        print(\"N° of true negatives: {}\".format(self.true_negative[index]))\n",
    "        print(\"N° of false positives: {}\".format(self.false_positive[index]))\n",
    "        \n",
    "        print(\"N° of predicted positives: {}\".format(self.predicted_positive[index]))\n",
    "        print(\"N° of predicted negatives: {}\".format(self.predicted_negative[index]))\n",
    "\n",
    "        print(\"-------------------advanced metrics----------------------\")\n",
    "\n",
    "        print(\"Precision: {}\".format(self.precision[index]))\n",
    "        print(\"Recall: {}\".format(self.recall[index]))\n",
    "        print(\"F1-score: {}\".format(self.f1[index]))\n",
    "\n",
    "        print(\"---------------------------------------------------------\")\n",
    "    \n",
    "    def show_metrics_k_acc(self, k, criterion: _TYPES =\"highest\"):\n",
    "        index_best = np.argsort(self.accuracy)[:k]\n",
    "        if criterion == \"lowest\":\n",
    "            index_best = np.argsort(self.accuracy)[-k:]\n",
    "        print(\"Showing metrics of {} {} accuracy classes\".format(criterion, k))\n",
    "        for index in index_best:\n",
    "            self.show_metrics(index)\n",
    "    \n",
    "    def show_metrics_k_tp(self, k, criterion: _TYPES =\"highest\"):\n",
    "        index_best = np.argsort(self.true_positive)[:k]\n",
    "        if criterion == \"lowest\":\n",
    "            index_best = np.argsort(self.true_positive)[-k:]\n",
    "        print(\"Showing metrics of {} {} true positives classes\".format(criterion, k))\n",
    "        for index in index_best:\n",
    "            self.show_metrics(index)\n",
    "    \n",
    "    def show_metrics_k_tn(self, k, criterion: _TYPES =\"highest\"):\n",
    "        index_best = np.argsort(self.true_negative)[:k]\n",
    "        if criterion == \"lowest\":\n",
    "            index_best = np.argsort(self.true_negative)[-k:]\n",
    "        print(\"Showing metrics of {} {} true negatives classes\".format(criterion, k))\n",
    "        for index in index_best:\n",
    "            self.show_metrics(index)\n",
    "    \n",
    "    def show_metrics_k_precision(self, k, criterion: _TYPES =\"highest\"):\n",
    "        index_best = np.argsort(self.precision)[:k]\n",
    "        if criterion == \"lowest\":\n",
    "            index_best = np.argsort(self.precision)[-k:]\n",
    "        print(\"Showing metrics of {} {} precision classes\".format(criterion, k))\n",
    "        for index in index_best:\n",
    "            self.show_metrics(index)\n",
    "    \n",
    "    def show_metrics_k_recall(self, k, criterion: _TYPES =\"highest\"):\n",
    "        index_best = np.argsort(self.recall)[:k]\n",
    "        if criterion == \"lowest\":\n",
    "            index_best = np.argsort(self.recall)[-k:]\n",
    "        print(\"Showing metrics of {} {} recall classes\".format(criterion, k))\n",
    "        for index in index_best:\n",
    "            self.show_metrics(index)\n",
    "    \n",
    "    def show_metrics_k_f1(self, k, criterion: _TYPES =\"highest\"):\n",
    "        index_best = np.argsort(self.f1)[:k]\n",
    "        if criterion == \"lowest\":\n",
    "            index_best = np.argsort(self.f1)[-k:]\n",
    "        print(\"Showing metrics of {} {} f1-score classes\".format(criterion, k))\n",
    "        for index in index_best:\n",
    "            self.show_metrics(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File is readable by numpy\n",
      "---------------------------------------------------------\n",
      "Showing metrics of class: beignet; filename:./misc/model_metrics/ConfM_Finetuned_FOOD101_ResNet50_Data_Augmentation_Origina_Weights_test_.npy\n",
      "Total accuracy of given cm: 35.05919575691223 %\n",
      "Best class: eggs_benedict; 56/65\n",
      "Worst class: knish; 0/48\n",
      "-------------------basic metrics------------------------\n",
      "Accuracy: 85.24590134620667 %\n",
      "N° of real positives: 61.0\n",
      "N° of true positives: 52.0\n",
      "N° of false negatives: 9.0\n",
      "N° of real negatives: 91.0\n",
      "N° of true negatives: 11894.0\n",
      "N° of false positives: 39.0\n",
      "N° of predicted positives: 91.0\n",
      "N° of predicted negatives: 11903.0\n",
      "-------------------advanced metrics----------------------\n",
      "Precision: 0.5714285969734192\n",
      "Recall: 0.8524590134620667\n",
      "F1-score: 0.6842105388641357\n",
      "---------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adriano\\AppData\\Local\\Temp\\ipykernel_11000\\434281237.py:61: RuntimeWarning: invalid value encountered in divide\n",
      "  self.precision = self.true_positive / self.predicted_positive\n",
      "C:\\Users\\Adriano\\AppData\\Local\\Temp\\ipykernel_11000\\434281237.py:65: RuntimeWarning: invalid value encountered in divide\n",
      "  self.f1 = 2*(self.precision * self.recall)/(self.precision + self.recall)\n"
     ]
    }
   ],
   "source": [
    "filename = \"./misc/model_metrics/{}.npy\".format(\"ConfM_Finetuned_FOOD101_ResNet50_Data_Augmentation_Origina_Weights_test_degraded\")\n",
    "classes = np.loadtxt(\"disambiguation.csv\", delimiter=\",\", dtype=\"str\")[:,1]\n",
    "# classes = [0,1,2,3]\n",
    "confusion_matrix = Confusion_Matrix_stats(filename, classes)\n",
    "confusion_matrix.show_metrics(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing metrics of highest 5 accuracy classes\n",
      "---------------------------------------------------------\n",
      "Showing metrics of class: osso_buco; filename:./misc/model_metrics/ConfM_Finetuned_FOOD101_ResNet50_Data_Augmentation_Origina_Weights_test_.npy\n",
      "Total accuracy of given cm: 35.05919575691223 %\n",
      "Best class: eggs_benedict; 56/65\n",
      "Worst class: knish; 0/48\n",
      "-------------------basic metrics------------------------\n",
      "Accuracy: 0.0 %\n",
      "N° of real positives: 42.0\n",
      "N° of true positives: 0.0\n",
      "N° of false negatives: 42.0\n",
      "N° of real negatives: 2.0\n",
      "N° of true negatives: 11950.0\n",
      "N° of false positives: 2.0\n",
      "N° of predicted positives: 2.0\n",
      "N° of predicted negatives: 11992.0\n",
      "-------------------advanced metrics----------------------\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-score: nan\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "Showing metrics of class: rock_cake; filename:./misc/model_metrics/ConfM_Finetuned_FOOD101_ResNet50_Data_Augmentation_Origina_Weights_test_.npy\n",
      "Total accuracy of given cm: 35.05919575691223 %\n",
      "Best class: eggs_benedict; 56/65\n",
      "Worst class: knish; 0/48\n",
      "-------------------basic metrics------------------------\n",
      "Accuracy: 0.0 %\n",
      "N° of real positives: 17.0\n",
      "N° of true positives: 0.0\n",
      "N° of false negatives: 17.0\n",
      "N° of real negatives: 3.0\n",
      "N° of true negatives: 11974.0\n",
      "N° of false positives: 3.0\n",
      "N° of predicted positives: 3.0\n",
      "N° of predicted negatives: 11991.0\n",
      "-------------------advanced metrics----------------------\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-score: nan\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "Showing metrics of class: bacon_and_eggs; filename:./misc/model_metrics/ConfM_Finetuned_FOOD101_ResNet50_Data_Augmentation_Origina_Weights_test_.npy\n",
      "Total accuracy of given cm: 35.05919575691223 %\n",
      "Best class: eggs_benedict; 56/65\n",
      "Worst class: knish; 0/48\n",
      "-------------------basic metrics------------------------\n",
      "Accuracy: 0.0 %\n",
      "N° of real positives: 43.0\n",
      "N° of true positives: 0.0\n",
      "N° of false negatives: 43.0\n",
      "N° of real negatives: 2.0\n",
      "N° of true negatives: 11949.0\n",
      "N° of false positives: 2.0\n",
      "N° of predicted positives: 2.0\n",
      "N° of predicted negatives: 11992.0\n",
      "-------------------advanced metrics----------------------\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-score: nan\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "Showing metrics of class: syllabub; filename:./misc/model_metrics/ConfM_Finetuned_FOOD101_ResNet50_Data_Augmentation_Origina_Weights_test_.npy\n",
      "Total accuracy of given cm: 35.05919575691223 %\n",
      "Best class: eggs_benedict; 56/65\n",
      "Worst class: knish; 0/48\n",
      "-------------------basic metrics------------------------\n",
      "Accuracy: 0.0 %\n",
      "N° of real positives: 48.0\n",
      "N° of true positives: 0.0\n",
      "N° of false negatives: 48.0\n",
      "N° of real negatives: 1.0\n",
      "N° of true negatives: 11945.0\n",
      "N° of false positives: 1.0\n",
      "N° of predicted positives: 1.0\n",
      "N° of predicted negatives: 11993.0\n",
      "-------------------advanced metrics----------------------\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-score: nan\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "Showing metrics of class: wonton; filename:./misc/model_metrics/ConfM_Finetuned_FOOD101_ResNet50_Data_Augmentation_Origina_Weights_test_.npy\n",
      "Total accuracy of given cm: 35.05919575691223 %\n",
      "Best class: eggs_benedict; 56/65\n",
      "Worst class: knish; 0/48\n",
      "-------------------basic metrics------------------------\n",
      "Accuracy: 0.0 %\n",
      "N° of real positives: 48.0\n",
      "N° of true positives: 0.0\n",
      "N° of false negatives: 48.0\n",
      "N° of real negatives: 7.0\n",
      "N° of true negatives: 11939.0\n",
      "N° of false positives: 7.0\n",
      "N° of predicted positives: 7.0\n",
      "N° of predicted negatives: 11987.0\n",
      "-------------------advanced metrics----------------------\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-score: nan\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix.show_metrics_k_acc(5, criterion = \"highest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the top k confused couples of classes\n",
      "#1: ('spring_roll', 'egg_roll'); has been confused 23 times\n",
      "#2: ('club_sandwich', 'bacon_lettuce_tomato_sandwich'); has been confused 22 times\n",
      "#3: ('coffee_cake', 'crumb_cake'); has been confused 22 times\n",
      "#4: ('baby_back_rib', 'barbecued_spareribs'); has been confused 22 times\n",
      "#5: ('linguine', 'spaghetti_carbonara'); has been confused 21 times\n",
      "#6: ('beef_tartare', 'steak_tartare'); has been confused 20 times\n",
      "#7: ('cannelloni', 'manicotti'); has been confused 20 times\n",
      "#8: ('fish_and_chips', 'fish_stick'); has been confused 19 times\n",
      "#9: ('spaghetti_carbonara', 'fettuccine'); has been confused 19 times\n",
      "#10: ('frittata', 'omelette'); has been confused 17 times\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(43, 59),\n",
       " (51, 232),\n",
       " (119, 227),\n",
       " (206, 240),\n",
       " (75, 134),\n",
       " (18, 83),\n",
       " (182, 192),\n",
       " (97, 226),\n",
       " (134, 142),\n",
       " (35, 196)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix.show_top_k_confused_classes(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.arange(251)\n",
    "\n",
    "rows = [\"{}\".format(i) for i in classes] \n",
    "text = \"\\n\".join(rows) \n",
    "  \n",
    "with open('disambiguation.csv', 'w') as f: \n",
    "    f.write(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
