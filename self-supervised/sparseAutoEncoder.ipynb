{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: progettoVIPM\n"
     ]
    }
   ],
   "source": [
    "if(os.path.split(os.getcwd())[1] == \"Transfer_Learning\" or os.path.split(os.getcwd())[1] == \"semi-supervised\" or os.path.split(os.getcwd())[1] == \"self-supervised\"):\n",
    "    os.chdir(\"..\")\n",
    "print(\"Current Working Directory: {}\".format(os.path.split(os.getcwd())[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.loadersAndEnums import datasets, ImageDataset\n",
    "from torch.utils.data import DataLoader, ConcatDataset, random_split\n",
    "\n",
    "trainL = ImageDataset(dataset=datasets.TRAINING_LABELED_80,network_input_size=256, cuda=cuda, normalize=True)\n",
    "trainU = ImageDataset(dataset=datasets.TRAINING_UNLABELED,network_input_size=256, cuda=cuda, normalize=True)\n",
    "trainC = ImageDataset(dataset=datasets.TRAINING_MIXED,network_input_size=256,cuda=cuda, normalize=True)\n",
    "train_size = int(0.8*len(trainC))\n",
    "val_size = len(trainC)-train_size\n",
    "train,val = random_split(trainC,[train_size,val_size])\n",
    "test = ImageDataset(dataset=datasets.TEST,network_input_size=256,cuda=cuda, normalize=True)\n",
    "valL = ImageDataset(dataset=datasets.VALIDATION_LABELED_20,network_input_size=256,cuda=cuda, normalize=True)\n",
    "\n",
    "trainL = DataLoader(trainL,128,True)\n",
    "train = DataLoader(train,128,True)\n",
    "val = DataLoader(val,128,True)\n",
    "test = DataLoader(test,128,True)\n",
    "valL = DataLoader(valL,128,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sparseAutoencoder import SparseAutoencoderL1\n",
    "\n",
    "sparseAE = SparseAutoencoderL1()\n",
    "\n",
    "optimizer = torch.optim.Adam(sparseAE.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()  # Reconstruction loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
